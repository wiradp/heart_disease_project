{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <b><font color='orange'> 1. Importing Data to Python </b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import library pengolahan struktur data\n",
    "import pandas as pd\n",
    "\n",
    "# Import library pengolahan angka\n",
    "import numpy as np\n",
    "\n",
    "# Import library untuk visualisasi\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Buat fungsi untuk mengimpor dataset\n",
    "def ImportData(data_file):\n",
    "    \"\"\"\n",
    "    Fungsi untuk import data & hapus duplikat\n",
    "    :param data_file: <string> nama file input (format .data)\n",
    "    :return heart_df: <pandas> sample data\n",
    "    \"\"\"\n",
    "    # Definisikan nama kolom sesuai dengan dokumentasi dataset\n",
    "    column_names = ['age', 'sex', 'cp', 'trestbps', 'chol', 'fbs', 'restecg', 'thalach', 'exang', 'oldpeak', 'slope', 'ca', 'thal', 'target']\n",
    "\n",
    "    # baca data\n",
    "    heart_df = pd.read_csv(data_file, names=column_names)\n",
    "\n",
    "    # cetak bentuk data\n",
    "    print('Data asli:',heart_df.shape, '-(#Observasi, #kolom)')\n",
    "    print('Jumlah baris',heart_df.shape[0], 'dan jumlah kolom',heart_df.shape[1])\n",
    "\n",
    "    # Cek data duplikat\n",
    "    duplicate_status = heart_df.duplicated(keep='first')\n",
    "\n",
    "    if duplicate_status.sum() == 0:\n",
    "        print('Tidak ada data duplikat')\n",
    "    else:\n",
    "        heart_df = heart_df.drop_duplicates()\n",
    "        print('Data setelah di-drop :', heart_df.shape, '-(#observasi, #kolom)')\n",
    "\n",
    "    return heart_df\n",
    "\n",
    "# (data_file) adalah argumen\n",
    "# Argumen adalah sebuah variable\n",
    "# Jika fungsi tersebut diberi argumen data_file = \"processed.cleveland.data\",\n",
    "# maka semua variable 'data_file' didalam fungsi akan berubah menjadi 'processed.cleveland.data'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data asli: (303, 14) -(#Observasi, #kolom)\n",
      "Jumlah baris 303 dan jumlah kolom 14\n",
      "Tidak ada data duplikat\n"
     ]
    }
   ],
   "source": [
    "# Input argumen\n",
    "data_file = 'processed.cleveland.data'\n",
    "\n",
    "# Panggil fungsi\n",
    "heart_df = ImportData(data_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>cp</th>\n",
       "      <th>trestbps</th>\n",
       "      <th>chol</th>\n",
       "      <th>fbs</th>\n",
       "      <th>restecg</th>\n",
       "      <th>thalach</th>\n",
       "      <th>exang</th>\n",
       "      <th>oldpeak</th>\n",
       "      <th>slope</th>\n",
       "      <th>ca</th>\n",
       "      <th>thal</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>63.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>145.0</td>\n",
       "      <td>233.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>150.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.3</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>67.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>160.0</td>\n",
       "      <td>286.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>108.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.5</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>67.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>120.0</td>\n",
       "      <td>229.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>129.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.6</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>37.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>130.0</td>\n",
       "      <td>250.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>187.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>41.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>130.0</td>\n",
       "      <td>204.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>172.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    age  sex   cp  trestbps   chol  fbs  restecg  thalach  exang  oldpeak  \\\n",
       "0  63.0  1.0  1.0     145.0  233.0  1.0      2.0    150.0    0.0      2.3   \n",
       "1  67.0  1.0  4.0     160.0  286.0  0.0      2.0    108.0    1.0      1.5   \n",
       "2  67.0  1.0  4.0     120.0  229.0  0.0      2.0    129.0    1.0      2.6   \n",
       "3  37.0  1.0  3.0     130.0  250.0  0.0      0.0    187.0    0.0      3.5   \n",
       "4  41.0  0.0  2.0     130.0  204.0  0.0      2.0    172.0    0.0      1.4   \n",
       "\n",
       "   slope   ca thal  target  \n",
       "0    3.0  0.0  6.0       0  \n",
       "1    2.0  3.0  3.0       2  \n",
       "2    2.0  2.0  7.0       1  \n",
       "3    3.0  0.0  3.0       0  \n",
       "4    1.0  0.0  3.0       0  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "heart_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <b><font color='orange'> 2. Data Preprocessing:</font></b>\n",
    "---\n",
    "* Input-Output Split, Train-Test Split\n",
    "* Processing Categorical\n",
    "* Imputation, Normalization, Drop Duplicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Jumlah Nilai</th>\n",
       "      <th>Nilai Unik</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>age</th>\n",
       "      <td>41</td>\n",
       "      <td>[63.0, 67.0, 37.0, 41.0, 56.0, 62.0, 57.0, 53....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sex</th>\n",
       "      <td>2</td>\n",
       "      <td>[1.0, 0.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cp</th>\n",
       "      <td>4</td>\n",
       "      <td>[1.0, 4.0, 3.0, 2.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>trestbps</th>\n",
       "      <td>50</td>\n",
       "      <td>[145.0, 160.0, 120.0, 130.0, 140.0, 172.0, 150...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>chol</th>\n",
       "      <td>152</td>\n",
       "      <td>[233.0, 286.0, 229.0, 250.0, 204.0, 236.0, 268...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fbs</th>\n",
       "      <td>2</td>\n",
       "      <td>[1.0, 0.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>restecg</th>\n",
       "      <td>3</td>\n",
       "      <td>[2.0, 0.0, 1.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>thalach</th>\n",
       "      <td>91</td>\n",
       "      <td>[150.0, 108.0, 129.0, 187.0, 172.0, 178.0, 160...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>exang</th>\n",
       "      <td>2</td>\n",
       "      <td>[0.0, 1.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>oldpeak</th>\n",
       "      <td>40</td>\n",
       "      <td>[2.3, 1.5, 2.6, 3.5, 1.4, 0.8, 3.6, 0.6, 3.1, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>slope</th>\n",
       "      <td>3</td>\n",
       "      <td>[3.0, 2.0, 1.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ca</th>\n",
       "      <td>5</td>\n",
       "      <td>[0.0, 3.0, 2.0, 1.0, ?]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>thal</th>\n",
       "      <td>4</td>\n",
       "      <td>[6.0, 3.0, 7.0, ?]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>target</th>\n",
       "      <td>5</td>\n",
       "      <td>[0, 2, 1, 3, 4]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Jumlah Nilai                                         Nilai Unik\n",
       "age                41  [63.0, 67.0, 37.0, 41.0, 56.0, 62.0, 57.0, 53....\n",
       "sex                 2                                         [1.0, 0.0]\n",
       "cp                  4                               [1.0, 4.0, 3.0, 2.0]\n",
       "trestbps           50  [145.0, 160.0, 120.0, 130.0, 140.0, 172.0, 150...\n",
       "chol              152  [233.0, 286.0, 229.0, 250.0, 204.0, 236.0, 268...\n",
       "fbs                 2                                         [1.0, 0.0]\n",
       "restecg             3                                    [2.0, 0.0, 1.0]\n",
       "thalach            91  [150.0, 108.0, 129.0, 187.0, 172.0, 178.0, 160...\n",
       "exang               2                                         [0.0, 1.0]\n",
       "oldpeak            40  [2.3, 1.5, 2.6, 3.5, 1.4, 0.8, 3.6, 0.6, 3.1, ...\n",
       "slope               3                                    [3.0, 2.0, 1.0]\n",
       "ca                  5                            [0.0, 3.0, 2.0, 1.0, ?]\n",
       "thal                4                                 [6.0, 3.0, 7.0, ?]\n",
       "target              5                                    [0, 2, 1, 3, 4]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Cek Jumlah nilai dan nilai unik pada setip kolom\n",
    "summary_dict = {}\n",
    "for i in list(heart_df.columns):\n",
    "    summary_dict[i] = {\n",
    "        'Jumlah Nilai': heart_df[i].value_counts().shape[0],\n",
    "        'Nilai Unik': heart_df[i].unique()\n",
    "    }\n",
    "summary_df = pd.DataFrame(summary_dict).T\n",
    "\n",
    "summary_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">Terdapat nilai **'?'** pada kolom `ca` dan `thal`. Kita perlu merubah nilai tersebut menjadi NA/NaN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Jumlah nilai \"?\" pada kolom ca   : 4\n",
      "Jumlah nilai \"?\" pada kolom thal : 2\n"
     ]
    }
   ],
   "source": [
    "print('Jumlah nilai \"?\" pada kolom ca   :', (heart_df['ca'] == '?').sum())\n",
    "print('Jumlah nilai \"?\" pada kolom thal :', (heart_df['thal'] == '?').sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>cp</th>\n",
       "      <th>trestbps</th>\n",
       "      <th>chol</th>\n",
       "      <th>fbs</th>\n",
       "      <th>restecg</th>\n",
       "      <th>thalach</th>\n",
       "      <th>exang</th>\n",
       "      <th>oldpeak</th>\n",
       "      <th>slope</th>\n",
       "      <th>ca</th>\n",
       "      <th>thal</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>87</th>\n",
       "      <td>53.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>128.0</td>\n",
       "      <td>216.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>115.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>?</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>166</th>\n",
       "      <td>52.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>138.0</td>\n",
       "      <td>223.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>169.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>?</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>192</th>\n",
       "      <td>43.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>132.0</td>\n",
       "      <td>247.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>143.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.1</td>\n",
       "      <td>2.0</td>\n",
       "      <td>?</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>266</th>\n",
       "      <td>52.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>128.0</td>\n",
       "      <td>204.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>156.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>?</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>287</th>\n",
       "      <td>58.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>125.0</td>\n",
       "      <td>220.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>144.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.4</td>\n",
       "      <td>2.0</td>\n",
       "      <td>?</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>302</th>\n",
       "      <td>38.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>138.0</td>\n",
       "      <td>175.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>173.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>?</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      age  sex   cp  trestbps   chol  fbs  restecg  thalach  exang  oldpeak  \\\n",
       "87   53.0  0.0  3.0     128.0  216.0  0.0      2.0    115.0    0.0      0.0   \n",
       "166  52.0  1.0  3.0     138.0  223.0  0.0      0.0    169.0    0.0      0.0   \n",
       "192  43.0  1.0  4.0     132.0  247.0  1.0      2.0    143.0    1.0      0.1   \n",
       "266  52.0  1.0  4.0     128.0  204.0  1.0      0.0    156.0    1.0      1.0   \n",
       "287  58.0  1.0  2.0     125.0  220.0  0.0      0.0    144.0    0.0      0.4   \n",
       "302  38.0  1.0  3.0     138.0  175.0  0.0      0.0    173.0    0.0      0.0   \n",
       "\n",
       "     slope   ca thal  target  \n",
       "87     1.0  0.0    ?       0  \n",
       "166    1.0    ?  3.0       0  \n",
       "192    2.0    ?  7.0       1  \n",
       "266    2.0  0.0    ?       2  \n",
       "287    2.0    ?  7.0       0  \n",
       "302    1.0    ?  3.0       0  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Lihat semua baris yang mengandung nilai '?'\n",
    "heart_df[heart_df.isin(['?']).any(axis=1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Penganganan missing value\n",
    "def handle_missing_value(data):\n",
    "    \"\"\"\n",
    "    Fungsi untuk menangani missing value yang ditandai dengan '?'\n",
    "    param df: <pandas dataframe> data input\n",
    "    return df: <pandas dataframe> data dengan missing value yang sudah diganti\n",
    "    \"\"\"\n",
    "    # Hapus baris dengan nilai'?'\n",
    "    # data = data[data != '?'].dropna()\n",
    "\n",
    "    # Ganti '?' dengan NaN\n",
    "    data.replace('?', np.NaN, inplace=True)\n",
    "\n",
    "    # Tampilkan jumlah missing value per kolom\n",
    "    print('Jumlah missing value setelah dihapus:\\n', data.isnull().sum())\n",
    "\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Jumlah missing value setelah dihapus:\n",
      " age         0\n",
      "sex         0\n",
      "cp          0\n",
      "trestbps    0\n",
      "chol        0\n",
      "fbs         0\n",
      "restecg     0\n",
      "thalach     0\n",
      "exang       0\n",
      "oldpeak     0\n",
      "slope       0\n",
      "ca          4\n",
      "thal        2\n",
      "target      0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Panggil fungsi untuk menangai missing value\n",
    "heart_df = handle_missing_value(heart_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nilai unik kolom ca   : ['0.0' '3.0' '2.0' '1.0' nan]\n",
      "Nilai unik kolom thal : ['6.0' '3.0' '7.0' nan]\n"
     ]
    }
   ],
   "source": [
    "print('Nilai unik kolom ca   :', heart_df['ca'].unique())\n",
    "print('Nilai unik kolom thal :', heart_df['thal'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>cp</th>\n",
       "      <th>trestbps</th>\n",
       "      <th>chol</th>\n",
       "      <th>fbs</th>\n",
       "      <th>restecg</th>\n",
       "      <th>thalach</th>\n",
       "      <th>exang</th>\n",
       "      <th>oldpeak</th>\n",
       "      <th>slope</th>\n",
       "      <th>ca</th>\n",
       "      <th>thal</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>87</th>\n",
       "      <td>53.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>128.0</td>\n",
       "      <td>216.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>115.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>166</th>\n",
       "      <td>52.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>138.0</td>\n",
       "      <td>223.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>169.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>192</th>\n",
       "      <td>43.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>132.0</td>\n",
       "      <td>247.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>143.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.1</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>266</th>\n",
       "      <td>52.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>128.0</td>\n",
       "      <td>204.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>156.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>287</th>\n",
       "      <td>58.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>125.0</td>\n",
       "      <td>220.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>144.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.4</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>302</th>\n",
       "      <td>38.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>138.0</td>\n",
       "      <td>175.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>173.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      age  sex   cp  trestbps   chol  fbs  restecg  thalach  exang  oldpeak  \\\n",
       "87   53.0  0.0  3.0     128.0  216.0  0.0      2.0    115.0    0.0      0.0   \n",
       "166  52.0  1.0  3.0     138.0  223.0  0.0      0.0    169.0    0.0      0.0   \n",
       "192  43.0  1.0  4.0     132.0  247.0  1.0      2.0    143.0    1.0      0.1   \n",
       "266  52.0  1.0  4.0     128.0  204.0  1.0      0.0    156.0    1.0      1.0   \n",
       "287  58.0  1.0  2.0     125.0  220.0  0.0      0.0    144.0    0.0      0.4   \n",
       "302  38.0  1.0  3.0     138.0  175.0  0.0      0.0    173.0    0.0      0.0   \n",
       "\n",
       "     slope   ca thal  target  \n",
       "87     1.0  0.0  NaN       0  \n",
       "166    1.0  NaN  3.0       0  \n",
       "192    2.0  NaN  7.0       1  \n",
       "266    2.0  0.0  NaN       2  \n",
       "287    2.0  NaN  7.0       0  \n",
       "302    1.0  NaN  3.0       0  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Lihat semua baris yang mempunyai nilai NaN\n",
    "heart_df[heart_df.isna().any(axis=1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "fill_missing_value = heart_df.fillna(value=\"KOSONG\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>cp</th>\n",
       "      <th>trestbps</th>\n",
       "      <th>chol</th>\n",
       "      <th>fbs</th>\n",
       "      <th>restecg</th>\n",
       "      <th>thalach</th>\n",
       "      <th>exang</th>\n",
       "      <th>oldpeak</th>\n",
       "      <th>slope</th>\n",
       "      <th>ca</th>\n",
       "      <th>thal</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>87</th>\n",
       "      <td>53.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>128.0</td>\n",
       "      <td>216.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>115.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>KOSONG</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>166</th>\n",
       "      <td>52.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>138.0</td>\n",
       "      <td>223.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>169.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>KOSONG</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>192</th>\n",
       "      <td>43.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>132.0</td>\n",
       "      <td>247.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>143.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.1</td>\n",
       "      <td>2.0</td>\n",
       "      <td>KOSONG</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>266</th>\n",
       "      <td>52.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>128.0</td>\n",
       "      <td>204.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>156.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>KOSONG</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>287</th>\n",
       "      <td>58.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>125.0</td>\n",
       "      <td>220.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>144.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.4</td>\n",
       "      <td>2.0</td>\n",
       "      <td>KOSONG</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>302</th>\n",
       "      <td>38.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>138.0</td>\n",
       "      <td>175.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>173.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>KOSONG</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      age  sex   cp  trestbps   chol  fbs  restecg  thalach  exang  oldpeak  \\\n",
       "87   53.0  0.0  3.0     128.0  216.0  0.0      2.0    115.0    0.0      0.0   \n",
       "166  52.0  1.0  3.0     138.0  223.0  0.0      0.0    169.0    0.0      0.0   \n",
       "192  43.0  1.0  4.0     132.0  247.0  1.0      2.0    143.0    1.0      0.1   \n",
       "266  52.0  1.0  4.0     128.0  204.0  1.0      0.0    156.0    1.0      1.0   \n",
       "287  58.0  1.0  2.0     125.0  220.0  0.0      0.0    144.0    0.0      0.4   \n",
       "302  38.0  1.0  3.0     138.0  175.0  0.0      0.0    173.0    0.0      0.0   \n",
       "\n",
       "     slope      ca    thal  target  \n",
       "87     1.0     0.0  KOSONG       0  \n",
       "166    1.0  KOSONG     3.0       0  \n",
       "192    2.0  KOSONG     7.0       1  \n",
       "266    2.0     0.0  KOSONG       2  \n",
       "287    2.0  KOSONG     7.0       0  \n",
       "302    1.0  KOSONG     3.0       0  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "heart_df = fill_missing_value\n",
    "\n",
    "heart_df[heart_df.isin([\"KOSONG\"]).any(axis=1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(303, 14)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "heart_df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Processing Categorical**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['age', 'sex', 'cp', 'trestbps', 'chol', 'fbs', 'restecg', 'thalach',\n",
      "       'exang', 'oldpeak', 'slope', 'ca', 'thal', 'target'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "# Cek nama kolom dataset\n",
    "print(heart_df.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Bedakan antara data categorical dengan numerical**\n",
    "\n",
    "Data Categorical\n",
    "- sex\n",
    "- cp\n",
    "- fbs\n",
    "- restecg\n",
    "- exang\n",
    "- slope\n",
    "- thal\n",
    "\n",
    "Sisanya adalah numerical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Buat kolom numerical dan categorical\n",
    "categorical_column = ['sex','cp','fbs','restecg','exang','slope','thal']\n",
    "\n",
    "numerical_column = ['age','trestbps','chol','thalach','oldpeak', 'target']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['sex', 'cp', 'fbs', 'restecg', 'exang', 'slope', 'thal']\n",
      "['age', 'trestbps', 'chol', 'thalach', 'oldpeak', 'target']\n"
     ]
    }
   ],
   "source": [
    "# Lihat hasil pengkategorian\n",
    "print(categorical_column)\n",
    "print(numerical_column)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "heart_df[categorical_column] = heart_df[categorical_column].astype('object')\n",
    "\n",
    "categorical_ohe = pd.get_dummies(heart_df[categorical_column], columns=categorical_column)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 303 entries, 0 to 302\n",
      "Data columns (total 20 columns):\n",
      " #   Column       Non-Null Count  Dtype\n",
      "---  ------       --------------  -----\n",
      " 0   sex_0.0      303 non-null    bool \n",
      " 1   sex_1.0      303 non-null    bool \n",
      " 2   cp_1.0       303 non-null    bool \n",
      " 3   cp_2.0       303 non-null    bool \n",
      " 4   cp_3.0       303 non-null    bool \n",
      " 5   cp_4.0       303 non-null    bool \n",
      " 6   fbs_0.0      303 non-null    bool \n",
      " 7   fbs_1.0      303 non-null    bool \n",
      " 8   restecg_0.0  303 non-null    bool \n",
      " 9   restecg_1.0  303 non-null    bool \n",
      " 10  restecg_2.0  303 non-null    bool \n",
      " 11  exang_0.0    303 non-null    bool \n",
      " 12  exang_1.0    303 non-null    bool \n",
      " 13  slope_1.0    303 non-null    bool \n",
      " 14  slope_2.0    303 non-null    bool \n",
      " 15  slope_3.0    303 non-null    bool \n",
      " 16  thal_3.0     303 non-null    bool \n",
      " 17  thal_6.0     303 non-null    bool \n",
      " 18  thal_7.0     303 non-null    bool \n",
      " 19  thal_KOSONG  303 non-null    bool \n",
      "dtypes: bool(20)\n",
      "memory usage: 6.0 KB\n"
     ]
    }
   ],
   "source": [
    "categorical_ohe.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "ohe_columns = categorical_ohe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Join data Numerical dan Categorical**\n",
    "- Data numerik & kategorik harus digabungkan kembali\n",
    "- Penggabungan dengan `pd.concat`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lakukan penggabungan data numerik dan data kategorik yang sudah di encoded\n",
    "heart_df_concat = pd.concat([heart_df[numerical_column], categorical_ohe], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>trestbps</th>\n",
       "      <th>chol</th>\n",
       "      <th>thalach</th>\n",
       "      <th>oldpeak</th>\n",
       "      <th>target</th>\n",
       "      <th>sex_0.0</th>\n",
       "      <th>sex_1.0</th>\n",
       "      <th>cp_1.0</th>\n",
       "      <th>cp_2.0</th>\n",
       "      <th>...</th>\n",
       "      <th>restecg_2.0</th>\n",
       "      <th>exang_0.0</th>\n",
       "      <th>exang_1.0</th>\n",
       "      <th>slope_1.0</th>\n",
       "      <th>slope_2.0</th>\n",
       "      <th>slope_3.0</th>\n",
       "      <th>thal_3.0</th>\n",
       "      <th>thal_6.0</th>\n",
       "      <th>thal_7.0</th>\n",
       "      <th>thal_KOSONG</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>63.0</td>\n",
       "      <td>145.0</td>\n",
       "      <td>233.0</td>\n",
       "      <td>150.0</td>\n",
       "      <td>2.3</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>67.0</td>\n",
       "      <td>160.0</td>\n",
       "      <td>286.0</td>\n",
       "      <td>108.0</td>\n",
       "      <td>1.5</td>\n",
       "      <td>2</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>67.0</td>\n",
       "      <td>120.0</td>\n",
       "      <td>229.0</td>\n",
       "      <td>129.0</td>\n",
       "      <td>2.6</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>37.0</td>\n",
       "      <td>130.0</td>\n",
       "      <td>250.0</td>\n",
       "      <td>187.0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>41.0</td>\n",
       "      <td>130.0</td>\n",
       "      <td>204.0</td>\n",
       "      <td>172.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>...</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 26 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    age  trestbps   chol  thalach  oldpeak  target  sex_0.0  sex_1.0  cp_1.0  \\\n",
       "0  63.0     145.0  233.0    150.0      2.3       0    False     True    True   \n",
       "1  67.0     160.0  286.0    108.0      1.5       2    False     True   False   \n",
       "2  67.0     120.0  229.0    129.0      2.6       1    False     True   False   \n",
       "3  37.0     130.0  250.0    187.0      3.5       0    False     True   False   \n",
       "4  41.0     130.0  204.0    172.0      1.4       0     True    False   False   \n",
       "\n",
       "   cp_2.0  ...  restecg_2.0  exang_0.0  exang_1.0  slope_1.0  slope_2.0  \\\n",
       "0   False  ...         True       True      False      False      False   \n",
       "1   False  ...         True      False       True      False       True   \n",
       "2   False  ...         True      False       True      False       True   \n",
       "3   False  ...        False       True      False      False      False   \n",
       "4    True  ...         True       True      False       True      False   \n",
       "\n",
       "   slope_3.0  thal_3.0  thal_6.0  thal_7.0  thal_KOSONG  \n",
       "0       True     False      True     False        False  \n",
       "1      False      True     False     False        False  \n",
       "2      False     False     False      True        False  \n",
       "3       True      True     False     False        False  \n",
       "4      False      True     False     False        False  \n",
       "\n",
       "[5 rows x 26 columns]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Cek hasil penggabungan\n",
    "heart_df_concat.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['age', 'trestbps', 'chol', 'thalach', 'oldpeak', 'target', 'sex_0.0',\n",
      "       'sex_1.0', 'cp_1.0', 'cp_2.0', 'cp_3.0', 'cp_4.0', 'fbs_0.0', 'fbs_1.0',\n",
      "       'restecg_0.0', 'restecg_1.0', 'restecg_2.0', 'exang_0.0', 'exang_1.0',\n",
      "       'slope_1.0', 'slope_2.0', 'slope_3.0', 'thal_3.0', 'thal_6.0',\n",
      "       'thal_7.0', 'thal_KOSONG'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print(heart_df_concat.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Jumlah missing value hasil penggabungan data numerik & kategorik: 0\n"
     ]
    }
   ],
   "source": [
    "# Cek nilai kosong hasil penggabungan\n",
    "print(f\"Jumlah missing value hasil penggabungan data numerik & kategorik: {heart_df_concat.isnull().any().sum()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Input-Output Split**\n",
    "\n",
    "- Fitur `y` adalah output variabel yaitu kolom 'target'\n",
    "- Fitur `x` adalah input variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def extractInputOutput(data, output_column_name, column_to_drop=None):\n",
    "def extractInputOutput(data, output_column_name):\n",
    "    \"\"\"\n",
    "    Fungsi untuk memisahkan data input dan output\n",
    "    :param data: <pandas dataframe> data seluruh sample\n",
    "    :param output_column_name: <string> nama kolom output\n",
    "    :param column_to_drop: daftar nama kolom yang ingin dihapus sebelum memisahkan\n",
    "    :return input_data: <pandas dataframe> data input, <pandas series> data output\n",
    "    \"\"\"\n",
    "    # drop data yang tidak diperlukan jika ada\n",
    "    # if column_to_drop:\n",
    "    #     data = data.drop(columns=column_to_drop)\n",
    "\n",
    "    # pisahkan data output\n",
    "    output_data = data[output_column_name]\n",
    "    \n",
    "    # drop kolom output dari data untuk mendapatkan input_data\n",
    "    input_data = data.drop(columns=output_column_name, axis=1)\n",
    "\n",
    "    return input_data, output_data\n",
    "\n",
    "# (data, output_column_name) adalah argumen\n",
    "# Argumen adalah sebuah variable\n",
    "# Jika fungsi tsb diberi argumen data = heart_df\n",
    "# maka semua variable 'data' didalam fungsi akan berubah menjadi heart_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Jalankan fungsi ekstak input output\n",
    "x, y = extractInputOutput(heart_df_concat, output_column_name='target')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Jumlah missing value variable input: 0\n",
      "Jumlah missing value variable output: 0\n"
     ]
    }
   ],
   "source": [
    "print(f\"Jumlah missing value variable input: {x.isnull().any().sum()}\")\n",
    "print(f\"Jumlah missing value variable output: {y.isnull().any().sum()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Train-Test Split**\n",
    "- **Kenapa?**\n",
    "    - Karena tidak ingin overfit data training\n",
    "    - Test data akan menjadi future data\n",
    "    - Kita akan melatih model ML di data training dengan CV (Cross Validation)\n",
    "    - Selanjutnya melakukan evaluasi di data testing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Train Test Split Function**\n",
    "1. `X` adalah input\n",
    "2. `y` adalah output (target)\n",
    "3. `test_size` adalah seberapa besar proporsi data test dari keseluruhan data. Contoh `test_size = 0.2` artinya data test akan berisi 20% data.\n",
    "4. `random_state` adalah kunci untuk random. Harus di-setting sama. Misal `random_state = 42`.\n",
    "5. Output:\n",
    "   - `x_train` = input dari data training\n",
    "   - `x_test` = input dari data testing\n",
    "   - `y_train` = output dari data training\n",
    "   - `y_test` = output dari data testing\n",
    "6. Urutan outputnya: `x_train, x_test, y_train, y_test`. Tidak boleh terbalik\n",
    "\n",
    "> Readmore: https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.train_test_split.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import train-test splitting library dari sklearn\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Train Test Split\n",
    "# Test size 0.20 atau 20%\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2,\n",
    "                                                    random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bentuk x_train (242, 25)\n",
      "Bentuk x_test  (61, 25)\n",
      "Bentuk y_train (242,)\n",
      "Bentuk y_test  (61,)\n"
     ]
    }
   ],
   "source": [
    "# Sanity chect hasil splitting\n",
    "print('Bentuk x_train', x_train.shape)\n",
    "print('Bentuk x_test ', x_test.shape)\n",
    "print('Bentuk y_train', y_train.shape)\n",
    "print('Bentuk y_test ',y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Jumlah kolom di x_train: 25\n",
      "Jumlah kolom di x_test: 25\n"
     ]
    }
   ],
   "source": [
    "# Cek apakah jumlah kolom sama\n",
    "print(f\"Jumlah kolom di x_train: {x_train.shape[1]}\")\n",
    "print(f\"Jumlah kolom di x_test: {x_test.shape[1]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Jumlah missing value di variable input x_train : 0\n",
      "Jumlah missing value di variable output y_train: 0\n"
     ]
    }
   ],
   "source": [
    "print(f\"Jumlah missing value di variable input x_train : {x_train.isnull().any().sum()}\") \n",
    "print(f\"Jumlah missing value di variable output y_train: {y_train.isnull().any().sum()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Standardizing Variables\n",
    "- Menyamakan skala dari variable input\n",
    "- `fit` : imputer agar mengetahui mean dan standar deviasi dari setiap kolom\n",
    "- `transform` : isi data dngan value yang sudah di normalisasi\n",
    "- output dari transform berupa pandas dataframe\n",
    "- normalize dikeluarkan karena akan digunakan pada data test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "# from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "data_columns = x_train.columns\n",
    "data_index = x_train.index\n",
    "\n",
    "\n",
    "scaler = StandardScaler()\n",
    "x_train_scaled = scaler.fit_transform(x_train)\n",
    "x_train_scaled = pd.DataFrame(x_train_scaled)\n",
    "x_train_scaled.columns = data_columns\n",
    "x_train_scaled.index = data_index\n",
    "# x_train_scaled.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>trestbps</th>\n",
       "      <th>chol</th>\n",
       "      <th>thalach</th>\n",
       "      <th>oldpeak</th>\n",
       "      <th>sex_0.0</th>\n",
       "      <th>sex_1.0</th>\n",
       "      <th>cp_1.0</th>\n",
       "      <th>cp_2.0</th>\n",
       "      <th>cp_3.0</th>\n",
       "      <th>...</th>\n",
       "      <th>restecg_2.0</th>\n",
       "      <th>exang_0.0</th>\n",
       "      <th>exang_1.0</th>\n",
       "      <th>slope_1.0</th>\n",
       "      <th>slope_2.0</th>\n",
       "      <th>slope_3.0</th>\n",
       "      <th>thal_3.0</th>\n",
       "      <th>thal_6.0</th>\n",
       "      <th>thal_7.0</th>\n",
       "      <th>thal_KOSONG</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>132</th>\n",
       "      <td>-2.838504</td>\n",
       "      <td>-0.125982</td>\n",
       "      <td>-0.864142</td>\n",
       "      <td>2.314470</td>\n",
       "      <td>-0.873573</td>\n",
       "      <td>-0.722504</td>\n",
       "      <td>0.722504</td>\n",
       "      <td>-0.316228</td>\n",
       "      <td>2.182179</td>\n",
       "      <td>-0.637947</td>\n",
       "      <td>...</td>\n",
       "      <td>1.016668</td>\n",
       "      <td>0.715891</td>\n",
       "      <td>-0.715891</td>\n",
       "      <td>1.050880</td>\n",
       "      <td>-0.912871</td>\n",
       "      <td>-0.274874</td>\n",
       "      <td>0.890277</td>\n",
       "      <td>-0.257059</td>\n",
       "      <td>-0.769484</td>\n",
       "      <td>-0.091287</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>202</th>\n",
       "      <td>0.241352</td>\n",
       "      <td>0.974653</td>\n",
       "      <td>-2.483637</td>\n",
       "      <td>1.021242</td>\n",
       "      <td>-0.704854</td>\n",
       "      <td>-0.722504</td>\n",
       "      <td>0.722504</td>\n",
       "      <td>-0.316228</td>\n",
       "      <td>-0.458258</td>\n",
       "      <td>1.567528</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.983605</td>\n",
       "      <td>0.715891</td>\n",
       "      <td>-0.715891</td>\n",
       "      <td>1.050880</td>\n",
       "      <td>-0.912871</td>\n",
       "      <td>-0.274874</td>\n",
       "      <td>-1.123246</td>\n",
       "      <td>-0.257059</td>\n",
       "      <td>1.299573</td>\n",
       "      <td>-0.091287</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>196</th>\n",
       "      <td>1.561291</td>\n",
       "      <td>1.524970</td>\n",
       "      <td>-0.241260</td>\n",
       "      <td>-0.851710</td>\n",
       "      <td>-0.789214</td>\n",
       "      <td>-0.722504</td>\n",
       "      <td>0.722504</td>\n",
       "      <td>3.162278</td>\n",
       "      <td>-0.458258</td>\n",
       "      <td>-0.637947</td>\n",
       "      <td>...</td>\n",
       "      <td>1.016668</td>\n",
       "      <td>0.715891</td>\n",
       "      <td>-0.715891</td>\n",
       "      <td>-0.951584</td>\n",
       "      <td>1.095445</td>\n",
       "      <td>-0.274874</td>\n",
       "      <td>0.890277</td>\n",
       "      <td>-0.257059</td>\n",
       "      <td>-0.769484</td>\n",
       "      <td>-0.091287</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <td>1.121311</td>\n",
       "      <td>1.524970</td>\n",
       "      <td>2.374848</td>\n",
       "      <td>0.040172</td>\n",
       "      <td>-0.198698</td>\n",
       "      <td>1.384075</td>\n",
       "      <td>-1.384075</td>\n",
       "      <td>-0.316228</td>\n",
       "      <td>-0.458258</td>\n",
       "      <td>1.567528</td>\n",
       "      <td>...</td>\n",
       "      <td>1.016668</td>\n",
       "      <td>0.715891</td>\n",
       "      <td>-0.715891</td>\n",
       "      <td>1.050880</td>\n",
       "      <td>-0.912871</td>\n",
       "      <td>-0.274874</td>\n",
       "      <td>0.890277</td>\n",
       "      <td>-0.257059</td>\n",
       "      <td>-0.769484</td>\n",
       "      <td>-0.091287</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>176</th>\n",
       "      <td>-0.308622</td>\n",
       "      <td>-1.336680</td>\n",
       "      <td>-0.262023</td>\n",
       "      <td>-0.138205</td>\n",
       "      <td>-0.789214</td>\n",
       "      <td>-0.722504</td>\n",
       "      <td>0.722504</td>\n",
       "      <td>-0.316228</td>\n",
       "      <td>-0.458258</td>\n",
       "      <td>-0.637947</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.983605</td>\n",
       "      <td>0.715891</td>\n",
       "      <td>-0.715891</td>\n",
       "      <td>1.050880</td>\n",
       "      <td>-0.912871</td>\n",
       "      <td>-0.274874</td>\n",
       "      <td>-1.123246</td>\n",
       "      <td>-0.257059</td>\n",
       "      <td>1.299573</td>\n",
       "      <td>-0.091287</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 25 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          age  trestbps      chol   thalach   oldpeak   sex_0.0   sex_1.0  \\\n",
       "132 -2.838504 -0.125982 -0.864142  2.314470 -0.873573 -0.722504  0.722504   \n",
       "202  0.241352  0.974653 -2.483637  1.021242 -0.704854 -0.722504  0.722504   \n",
       "196  1.561291  1.524970 -0.241260 -0.851710 -0.789214 -0.722504  0.722504   \n",
       "75   1.121311  1.524970  2.374848  0.040172 -0.198698  1.384075 -1.384075   \n",
       "176 -0.308622 -1.336680 -0.262023 -0.138205 -0.789214 -0.722504  0.722504   \n",
       "\n",
       "       cp_1.0    cp_2.0    cp_3.0  ...  restecg_2.0  exang_0.0  exang_1.0  \\\n",
       "132 -0.316228  2.182179 -0.637947  ...     1.016668   0.715891  -0.715891   \n",
       "202 -0.316228 -0.458258  1.567528  ...    -0.983605   0.715891  -0.715891   \n",
       "196  3.162278 -0.458258 -0.637947  ...     1.016668   0.715891  -0.715891   \n",
       "75  -0.316228 -0.458258  1.567528  ...     1.016668   0.715891  -0.715891   \n",
       "176 -0.316228 -0.458258 -0.637947  ...    -0.983605   0.715891  -0.715891   \n",
       "\n",
       "     slope_1.0  slope_2.0  slope_3.0  thal_3.0  thal_6.0  thal_7.0  \\\n",
       "132   1.050880  -0.912871  -0.274874  0.890277 -0.257059 -0.769484   \n",
       "202   1.050880  -0.912871  -0.274874 -1.123246 -0.257059  1.299573   \n",
       "196  -0.951584   1.095445  -0.274874  0.890277 -0.257059 -0.769484   \n",
       "75    1.050880  -0.912871  -0.274874  0.890277 -0.257059 -0.769484   \n",
       "176   1.050880  -0.912871  -0.274874 -1.123246 -0.257059  1.299573   \n",
       "\n",
       "     thal_KOSONG  \n",
       "132    -0.091287  \n",
       "202    -0.091287  \n",
       "196    -0.091287  \n",
       "75     -0.091287  \n",
       "176    -0.091287  \n",
       "\n",
       "[5 rows x 25 columns]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train_scaled.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <b><font color='orange'> 3. Training Machine Learning:</font></b>\n",
    "---\n",
    "        - Kita harus mengalahkan benchmark"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Benchmark / Baseline**\n",
    "- Baseline untuk evaluasi nanti\n",
    "- Karena ini klarifikasi, bisa kita ambil dari proporsi kelas target yang terbesar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "target\n",
       "0    0.557851\n",
       "1    0.177686\n",
       "3    0.115702\n",
       "2    0.111570\n",
       "4    0.037190\n",
       "Name: proportion, dtype: float64"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "benchmark = y_train.value_counts(normalize=True)\n",
    "benchmark"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Import Model\n",
    "- Kita akan gunakan 3 model ML untuk klarifikasi:\n",
    "    - K-nearest neighbor (K-NN)\n",
    "    - Logistic Regression\n",
    "    - Random Forest\n",
    "    - Adaboost\n",
    "    - SVC\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score, classification_report,confusion_matrix\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Fitting Model, Cek Performa & Prediksi\n",
    "- Cara fitting / training model mengikuti yang dokumentasi model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Akurasi pada data training : 0.6611570247933884\n",
      "Classification report      :\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.91      0.85       135\n",
      "           1       0.37      0.33      0.35        43\n",
      "           2       0.35      0.30      0.32        27\n",
      "           3       0.56      0.50      0.53        28\n",
      "           4       0.33      0.11      0.17         9\n",
      "\n",
      "    accuracy                           0.66       242\n",
      "   macro avg       0.48      0.43      0.44       242\n",
      "weighted avg       0.63      0.66      0.64       242\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Model Logistic Regression\n",
    "logreg = LogisticRegression(random_state=123)\n",
    "logreg.fit(x_train_scaled, y_train) # Latih model menggunakan data yang sudah di-scalling\n",
    "\n",
    "y_pred_logreg = logreg.predict(x_train_scaled)\n",
    "print('Akurasi pada data training :',accuracy_score(y_train, y_pred_logreg))\n",
    "print('Classification report      :\\n',classification_report(y_train, y_pred_logreg))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Insight**\n",
    "\n",
    "Logistic Regression:\n",
    "- Akurasi: 66.1%\n",
    "- Model ini tidak dapat memprediksi kelas yang lebih kecil dengan baik (misalnya, kelas 1, 2, dan 4). Kelas 0 mendominasi, dan performa untuk kelas lainnya cukup buruk.\n",
    "- Kesimpulan: Logistic Regression tidak bekerja dengan baik pada dataset ini, terutama pada kelas yang kurang terwakili."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Akurasi pada data training : 0.71900826446281\n",
      "Classification report      :\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.96      0.86       135\n",
      "           1       0.64      0.53      0.58        43\n",
      "           2       0.48      0.37      0.42        27\n",
      "           3       0.56      0.36      0.43        28\n",
      "           4       1.00      0.11      0.20         9\n",
      "\n",
      "    accuracy                           0.72       242\n",
      "   macro avg       0.69      0.47      0.50       242\n",
      "weighted avg       0.70      0.72      0.69       242\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Model K-nearst neighbor (KNN)\n",
    "knn = KNeighborsClassifier()\n",
    "knn.fit(x_train_scaled, y_train)\n",
    "\n",
    "y_pred_knn = knn.predict(x_train_scaled)\n",
    "print('Akurasi pada data training :',accuracy_score(y_train, y_pred_knn))\n",
    "print('Classification report      :\\n',classification_report(y_train, y_pred_knn))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Insight**\n",
    "\n",
    "K-Nearest Neighbors (KNN):\n",
    "- Akurasi: 71.9%\n",
    "- Model cukup baik dalam memprediksi kelas dominan (kelas 0). Namun, kinerja untuk kelas lainnya tetap terbatas.\n",
    "- Kesimpulan: KNN bisa menangani dataset ini dengan lebih baik dari Logistic Regression, tapi masih sensitif terhadap outlier dan kelas yang tidak seimbang."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Akurasi pada data training : 1.0\n",
      "Classification report      :\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       135\n",
      "           1       1.00      1.00      1.00        43\n",
      "           2       1.00      1.00      1.00        27\n",
      "           3       1.00      1.00      1.00        28\n",
      "           4       1.00      1.00      1.00         9\n",
      "\n",
      "    accuracy                           1.00       242\n",
      "   macro avg       1.00      1.00      1.00       242\n",
      "weighted avg       1.00      1.00      1.00       242\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Model Random Forest\n",
    "random_forest = RandomForestClassifier(random_state=123)\n",
    "random_forest.fit(x_train_scaled, y_train)\n",
    "\n",
    "y_pred_rf = random_forest.predict(x_train_scaled)\n",
    "print('Akurasi pada data training :',accuracy_score(y_train, y_pred_rf))\n",
    "print('Classification report      :\\n',classification_report(y_train, y_pred_rf))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Insight**\n",
    "\n",
    "Random Forest:\n",
    "\n",
    "- Akurasi: 100%\n",
    "- Model ini overfitting pada data training. Semua kelas diprediksi dengan sempurna pada data training.\n",
    "- Kesimpulan: Random Forest mempelajari data training dengan sangat baik, tetapi kemungkinan besar tidak akan generalisasi dengan baik pada data uji."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Akurasi pada data training : 0.6652892561983471\n",
      "Classification report      :\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.81      0.82       135\n",
      "           1       0.43      0.51      0.47        43\n",
      "           2       0.38      0.30      0.33        27\n",
      "           3       0.48      0.54      0.51        28\n",
      "           4       0.86      0.67      0.75         9\n",
      "\n",
      "    accuracy                           0.67       242\n",
      "   macro avg       0.60      0.57      0.58       242\n",
      "weighted avg       0.67      0.67      0.67       242\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Model AdaBosst\n",
    "adaboost = AdaBoostClassifier(random_state=123)\n",
    "adaboost.fit(x_train_scaled, y_train)\n",
    "\n",
    "y_pred_ada = adaboost.predict(x_train_scaled)\n",
    "print('Akurasi pada data training :',accuracy_score(y_train, y_pred_ada))\n",
    "print('Classification report      :\\n',classification_report(y_train, y_pred_ada))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Insight**\n",
    "\n",
    "AdaBoost:\n",
    "\n",
    "- Akurasi: 66.5%\n",
    "- Performa cukup merata di semua kelas, meskipun kelas minoritas tetap tidak diprediksi dengan baik.\n",
    "- Kesimpulan: AdaBoost tampaknya memberikan hasil yang lebih seimbang dibanding model lainnya, meskipun akurasi keseluruhannya tidak terlalu tinggi."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Akurasi pada data training : 0.756198347107438\n",
      "Classification report      :\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.99      0.86       135\n",
      "           1       0.56      0.44      0.49        43\n",
      "           2       1.00      0.44      0.62        27\n",
      "           3       1.00      0.54      0.70        28\n",
      "           4       1.00      0.33      0.50         9\n",
      "\n",
      "    accuracy                           0.76       242\n",
      "   macro avg       0.86      0.55      0.63       242\n",
      "weighted avg       0.78      0.76      0.73       242\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Model Support Vector Classification\n",
    "svc = SVC(kernel='poly')\n",
    "svc.fit(x_train_scaled, y_train)\n",
    "\n",
    "y_pred_svc = svc.predict(x_train_scaled)\n",
    "print('Akurasi pada data training :',accuracy_score(y_train, y_pred_svc))\n",
    "print('Classification report      :\\n',classification_report(y_train, y_pred_svc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Insight**\n",
    "\n",
    "Support Vector Classification (SVC):\n",
    "\n",
    "- Akurasi: 75.2%\n",
    "- Model ini memiliki kinerja terbaik dari segi akurasi. Namun, seperti model lain, performa pada kelas minoritas (kelas 1, 2, dan 4) masih terbatas.\n",
    "- Kesimpulan: SVC memberikan hasil yang paling baik di antara model-model lain, namun masih membutuhkan perbaikan dalam hal penanganan kelas minoritas."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Simpan model ke file pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['svc.pkl']"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import joblib\n",
    "\n",
    "# Simpan model logreg ke dalam folder yang sama dengan notebook\n",
    "# dengan nama logreg.pkl\n",
    "joblib.dump(knn, 'knn.pkl')\n",
    "joblib.dump(logreg, 'logreg.pkl')\n",
    "joblib.dump(random_forest, 'rf.pkl')\n",
    "joblib.dump(adaboost, 'ada.pkl')\n",
    "joblib.dump(svc, 'svc.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Test Prediction\n",
    "1. Siapkan file test dataset\n",
    "2. Lakukan preprocessing yang sama dengan yang dilakukan di train dataset\n",
    "3. Gunakan `imputer_numerical` jika ada data yang kosong dan `scaler` yang telah di fit di train dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>trestbps</th>\n",
       "      <th>chol</th>\n",
       "      <th>thalach</th>\n",
       "      <th>oldpeak</th>\n",
       "      <th>sex_0.0</th>\n",
       "      <th>sex_1.0</th>\n",
       "      <th>cp_1.0</th>\n",
       "      <th>cp_2.0</th>\n",
       "      <th>cp_3.0</th>\n",
       "      <th>...</th>\n",
       "      <th>restecg_2.0</th>\n",
       "      <th>exang_0.0</th>\n",
       "      <th>exang_1.0</th>\n",
       "      <th>slope_1.0</th>\n",
       "      <th>slope_2.0</th>\n",
       "      <th>slope_3.0</th>\n",
       "      <th>thal_3.0</th>\n",
       "      <th>thal_6.0</th>\n",
       "      <th>thal_7.0</th>\n",
       "      <th>thal_KOSONG</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>179</th>\n",
       "      <td>53.0</td>\n",
       "      <td>130.0</td>\n",
       "      <td>246.0</td>\n",
       "      <td>173.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>...</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>228</th>\n",
       "      <td>54.0</td>\n",
       "      <td>110.0</td>\n",
       "      <td>206.0</td>\n",
       "      <td>108.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>111</th>\n",
       "      <td>56.0</td>\n",
       "      <td>125.0</td>\n",
       "      <td>249.0</td>\n",
       "      <td>144.0</td>\n",
       "      <td>1.2</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>246</th>\n",
       "      <td>58.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>234.0</td>\n",
       "      <td>156.0</td>\n",
       "      <td>0.1</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>51.0</td>\n",
       "      <td>130.0</td>\n",
       "      <td>305.0</td>\n",
       "      <td>142.0</td>\n",
       "      <td>1.2</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 25 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      age  trestbps   chol  thalach  oldpeak  sex_0.0  sex_1.0  cp_1.0  \\\n",
       "179  53.0     130.0  246.0    173.0      0.0    False     True   False   \n",
       "228  54.0     110.0  206.0    108.0      0.0    False     True   False   \n",
       "111  56.0     125.0  249.0    144.0      1.2    False     True   False   \n",
       "246  58.0     100.0  234.0    156.0      0.1    False     True   False   \n",
       "60   51.0     130.0  305.0    142.0      1.2     True    False   False   \n",
       "\n",
       "     cp_2.0  cp_3.0  ...  restecg_2.0  exang_0.0  exang_1.0  slope_1.0  \\\n",
       "179   False    True  ...         True       True      False       True   \n",
       "228   False   False  ...         True      False       True      False   \n",
       "111   False   False  ...         True      False       True      False   \n",
       "246   False   False  ...        False       True      False       True   \n",
       "60    False   False  ...        False      False       True      False   \n",
       "\n",
       "     slope_2.0  slope_3.0  thal_3.0  thal_6.0  thal_7.0  thal_KOSONG  \n",
       "179      False      False      True     False     False        False  \n",
       "228       True      False      True     False     False        False  \n",
       "111       True      False      True     False     False        False  \n",
       "246      False      False     False     False      True        False  \n",
       "60        True      False     False     False      True        False  \n",
       "\n",
       "[5 rows x 25 columns]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test_scaled = pd.DataFrame(scaler.transform(x_test),columns=x_test.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>trestbps</th>\n",
       "      <th>chol</th>\n",
       "      <th>thalach</th>\n",
       "      <th>oldpeak</th>\n",
       "      <th>sex_0.0</th>\n",
       "      <th>sex_1.0</th>\n",
       "      <th>cp_1.0</th>\n",
       "      <th>cp_2.0</th>\n",
       "      <th>cp_3.0</th>\n",
       "      <th>...</th>\n",
       "      <th>restecg_2.0</th>\n",
       "      <th>exang_0.0</th>\n",
       "      <th>exang_1.0</th>\n",
       "      <th>slope_1.0</th>\n",
       "      <th>slope_2.0</th>\n",
       "      <th>slope_3.0</th>\n",
       "      <th>thal_3.0</th>\n",
       "      <th>thal_6.0</th>\n",
       "      <th>thal_7.0</th>\n",
       "      <th>thal_KOSONG</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.198627</td>\n",
       "      <td>-0.125982</td>\n",
       "      <td>0.007893</td>\n",
       "      <td>1.021242</td>\n",
       "      <td>-0.873573</td>\n",
       "      <td>-0.722504</td>\n",
       "      <td>0.722504</td>\n",
       "      <td>-0.316228</td>\n",
       "      <td>-0.458258</td>\n",
       "      <td>1.567528</td>\n",
       "      <td>...</td>\n",
       "      <td>1.016668</td>\n",
       "      <td>0.715891</td>\n",
       "      <td>-0.715891</td>\n",
       "      <td>1.050880</td>\n",
       "      <td>-0.912871</td>\n",
       "      <td>-0.274874</td>\n",
       "      <td>0.890277</td>\n",
       "      <td>-0.257059</td>\n",
       "      <td>-0.769484</td>\n",
       "      <td>-0.091287</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.088632</td>\n",
       "      <td>-1.226617</td>\n",
       "      <td>-0.822617</td>\n",
       "      <td>-1.877375</td>\n",
       "      <td>-0.873573</td>\n",
       "      <td>-0.722504</td>\n",
       "      <td>0.722504</td>\n",
       "      <td>-0.316228</td>\n",
       "      <td>-0.458258</td>\n",
       "      <td>-0.637947</td>\n",
       "      <td>...</td>\n",
       "      <td>1.016668</td>\n",
       "      <td>-1.396861</td>\n",
       "      <td>1.396861</td>\n",
       "      <td>-0.951584</td>\n",
       "      <td>1.095445</td>\n",
       "      <td>-0.274874</td>\n",
       "      <td>0.890277</td>\n",
       "      <td>-0.257059</td>\n",
       "      <td>-0.769484</td>\n",
       "      <td>-0.091287</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.131357</td>\n",
       "      <td>-0.401140</td>\n",
       "      <td>0.070182</td>\n",
       "      <td>-0.271987</td>\n",
       "      <td>0.138740</td>\n",
       "      <td>-0.722504</td>\n",
       "      <td>0.722504</td>\n",
       "      <td>-0.316228</td>\n",
       "      <td>-0.458258</td>\n",
       "      <td>-0.637947</td>\n",
       "      <td>...</td>\n",
       "      <td>1.016668</td>\n",
       "      <td>-1.396861</td>\n",
       "      <td>1.396861</td>\n",
       "      <td>-0.951584</td>\n",
       "      <td>1.095445</td>\n",
       "      <td>-0.274874</td>\n",
       "      <td>0.890277</td>\n",
       "      <td>-0.257059</td>\n",
       "      <td>-0.769484</td>\n",
       "      <td>-0.091287</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.351347</td>\n",
       "      <td>-1.776934</td>\n",
       "      <td>-0.241260</td>\n",
       "      <td>0.263142</td>\n",
       "      <td>-0.789214</td>\n",
       "      <td>-0.722504</td>\n",
       "      <td>0.722504</td>\n",
       "      <td>-0.316228</td>\n",
       "      <td>-0.458258</td>\n",
       "      <td>-0.637947</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.983605</td>\n",
       "      <td>0.715891</td>\n",
       "      <td>-0.715891</td>\n",
       "      <td>1.050880</td>\n",
       "      <td>-0.912871</td>\n",
       "      <td>-0.274874</td>\n",
       "      <td>-1.123246</td>\n",
       "      <td>-0.257059</td>\n",
       "      <td>1.299573</td>\n",
       "      <td>-0.091287</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.418617</td>\n",
       "      <td>-0.125982</td>\n",
       "      <td>1.232896</td>\n",
       "      <td>-0.361175</td>\n",
       "      <td>0.138740</td>\n",
       "      <td>1.384075</td>\n",
       "      <td>-1.384075</td>\n",
       "      <td>-0.316228</td>\n",
       "      <td>-0.458258</td>\n",
       "      <td>-0.637947</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.983605</td>\n",
       "      <td>-1.396861</td>\n",
       "      <td>1.396861</td>\n",
       "      <td>-0.951584</td>\n",
       "      <td>1.095445</td>\n",
       "      <td>-0.274874</td>\n",
       "      <td>-1.123246</td>\n",
       "      <td>-0.257059</td>\n",
       "      <td>1.299573</td>\n",
       "      <td>-0.091287</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 25 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        age  trestbps      chol   thalach   oldpeak   sex_0.0   sex_1.0  \\\n",
       "0 -0.198627 -0.125982  0.007893  1.021242 -0.873573 -0.722504  0.722504   \n",
       "1 -0.088632 -1.226617 -0.822617 -1.877375 -0.873573 -0.722504  0.722504   \n",
       "2  0.131357 -0.401140  0.070182 -0.271987  0.138740 -0.722504  0.722504   \n",
       "3  0.351347 -1.776934 -0.241260  0.263142 -0.789214 -0.722504  0.722504   \n",
       "4 -0.418617 -0.125982  1.232896 -0.361175  0.138740  1.384075 -1.384075   \n",
       "\n",
       "     cp_1.0    cp_2.0    cp_3.0  ...  restecg_2.0  exang_0.0  exang_1.0  \\\n",
       "0 -0.316228 -0.458258  1.567528  ...     1.016668   0.715891  -0.715891   \n",
       "1 -0.316228 -0.458258 -0.637947  ...     1.016668  -1.396861   1.396861   \n",
       "2 -0.316228 -0.458258 -0.637947  ...     1.016668  -1.396861   1.396861   \n",
       "3 -0.316228 -0.458258 -0.637947  ...    -0.983605   0.715891  -0.715891   \n",
       "4 -0.316228 -0.458258 -0.637947  ...    -0.983605  -1.396861   1.396861   \n",
       "\n",
       "   slope_1.0  slope_2.0  slope_3.0  thal_3.0  thal_6.0  thal_7.0  thal_KOSONG  \n",
       "0   1.050880  -0.912871  -0.274874  0.890277 -0.257059 -0.769484    -0.091287  \n",
       "1  -0.951584   1.095445  -0.274874  0.890277 -0.257059 -0.769484    -0.091287  \n",
       "2  -0.951584   1.095445  -0.274874  0.890277 -0.257059 -0.769484    -0.091287  \n",
       "3   1.050880  -0.912871  -0.274874 -1.123246 -0.257059  1.299573    -0.091287  \n",
       "4  -0.951584   1.095445  -0.274874 -1.123246 -0.257059  1.299573    -0.091287  \n",
       "\n",
       "[5 rows x 25 columns]"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_test_scaled.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Akurasi pada data test : 0.4262295081967213\n",
      "Classification report  :\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.73      0.83      0.77        29\n",
      "           1       0.00      0.00      0.00        12\n",
      "           2       0.00      0.00      0.00         9\n",
      "           3       0.13      0.29      0.18         7\n",
      "           4       0.00      0.00      0.00         4\n",
      "\n",
      "    accuracy                           0.43        61\n",
      "   macro avg       0.17      0.22      0.19        61\n",
      "weighted avg       0.36      0.43      0.39        61\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Model Logistic Regression\n",
    "logreg = LogisticRegression(random_state=123)\n",
    "logreg.fit(x_train_scaled, y_train) # Latih model menggunakan data yang sudah di-scalling\n",
    "\n",
    "y_pred_test_logreg = logreg.predict(x_test_scaled)\n",
    "print('Akurasi pada data test :',accuracy_score(y_test, y_pred_test_logreg))\n",
    "print('Classification report  :\\n',classification_report(y_test, y_pred_test_logreg))\n",
    "\n",
    "# Confusion matrix\n",
    "# print('Confusion matrix :\\n', confusion_matrix(y_test, y_pred_test_logreg))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Insight**\n",
    "- Akurasi: 42.6%\n",
    "- Kelas yang lebih kecil hampir tidak diprediksi sama sekali (precision, recall, dan f1-score untuk kelas 1, 2, dan 4 sangat buruk).\n",
    "- Kesimpulan: Logistic Regression tampak tidak bekerja dengan baik untuk dataset ini. Overfitting tidak terjadi, tetapi model tidak mampu mempelajari pola dari data yang kompleks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Akurasi pada data test : 0.5081967213114754\n",
      "Classification report  :\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.71      0.86      0.78        29\n",
      "           1       0.25      0.25      0.25        12\n",
      "           2       0.17      0.11      0.13         9\n",
      "           3       0.25      0.29      0.27         7\n",
      "           4       0.00      0.00      0.00         4\n",
      "\n",
      "    accuracy                           0.51        61\n",
      "   macro avg       0.28      0.30      0.29        61\n",
      "weighted avg       0.44      0.51      0.47        61\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Model K-nearst neighbor (KNN)\n",
    "knn = KNeighborsClassifier()\n",
    "knn.fit(x_train_scaled, y_train)\n",
    "\n",
    "y_pred_test_knn = knn.predict(x_test_scaled)\n",
    "print('Akurasi pada data test :',accuracy_score(y_test, y_pred_test_knn))\n",
    "print('Classification report  :\\n',classification_report(y_test, y_pred_test_knn))\n",
    "\n",
    "# Confusion matrix\n",
    "# print('Confusion matrix :\\n', confusion_matrix(y_test, y_pred_test_knn))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Insight**\n",
    "- Akurasi: 50.8%\n",
    "- Menunjukkan penurunan kinerja, tetapi sedikit lebih baik dibanding Logistic Regression. Precision, recall, dan f1-score untuk kelas 1 dan kelas minoritas tetap rendah.\n",
    "- Kesimpulan: KNN memiliki performa yang lebih baik dibanding Logistic Regression, tetapi masih menunjukkan kelemahan dalam menangani kelas minoritas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Akurasi pada data test : 0.5081967213114754\n",
      "Classification report  :\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      0.93      0.84        29\n",
      "           1       0.11      0.08      0.10        12\n",
      "           2       0.20      0.22      0.21         9\n",
      "           3       0.14      0.14      0.14         7\n",
      "           4       0.00      0.00      0.00         4\n",
      "\n",
      "    accuracy                           0.51        61\n",
      "   macro avg       0.25      0.28      0.26        61\n",
      "weighted avg       0.43      0.51      0.47        61\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Model Random Forest\n",
    "random_forest = RandomForestClassifier(random_state=123)\n",
    "random_forest.fit(x_train_scaled, y_train)\n",
    "\n",
    "y_pred_test_rf = random_forest.predict(x_test_scaled)\n",
    "print('Akurasi pada data test :',accuracy_score(y_test, y_pred_test_rf))\n",
    "print('Classification report  :\\n',classification_report(y_test, y_pred_test_rf))\n",
    "\n",
    "# Confusion matrix\n",
    "# print('Confusion matrix :\\n', confusion_matrix(y_test, y_pred_test_rf))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Insight**\n",
    "- Akurasi: 50.8%\n",
    "- Meskipun lebih tinggi daripada Logistic Regression, performanya masih tidak ideal pada kelas minoritas, terutama pada kelas 1 dan 4.\n",
    "- Kesimpulan: Random Forest overfitting pada data training. Meski lebih baik dari Logistic Regression dan KNN pada data test, model ini tidak generalisasi dengan baik."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Akurasi pada data test : 0.5245901639344263\n",
      "Classification report  :\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.74      0.86      0.79        29\n",
      "           1       0.29      0.17      0.21        12\n",
      "           2       0.30      0.33      0.32         9\n",
      "           3       0.20      0.29      0.24         7\n",
      "           4       0.00      0.00      0.00         4\n",
      "\n",
      "    accuracy                           0.52        61\n",
      "   macro avg       0.30      0.33      0.31        61\n",
      "weighted avg       0.47      0.52      0.49        61\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Model AdaBosst\n",
    "adaboost = AdaBoostClassifier(random_state=123)\n",
    "adaboost.fit(x_train_scaled, y_train)\n",
    "\n",
    "y_pred_test_ada = adaboost.predict(x_test_scaled)\n",
    "print('Akurasi pada data test :',accuracy_score(y_test, y_pred_test_ada))\n",
    "print('Classification report  :\\n',classification_report(y_test, y_pred_test_ada))\n",
    "\n",
    "# Confusion matrix\n",
    "# print('Confusion matrix :\\n', confusion_matrix(y_test, y_pred_test_ada))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Insight**\n",
    "- Akurasi: 52.4%\n",
    "- Kinerja pada kelas minoritas (kelas 1, 2, dan 4) lebih baik dibandingkan model lainnya, tetapi masih kurang optimal.\n",
    "- Kesimpulan: AdaBoost tampaknya memberikan hasil yang lebih seimbang dibanding model lainnya, meskipun akurasi keseluruhannya tidak terlalu tinggi."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Akurasi pada data test : 0.47540983606557374\n",
      "Classification report  :\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.62      0.90      0.73        29\n",
      "           1       0.12      0.08      0.10        12\n",
      "           2       0.50      0.11      0.18         9\n",
      "           3       0.11      0.14      0.12         7\n",
      "           4       0.00      0.00      0.00         4\n",
      "\n",
      "    accuracy                           0.48        61\n",
      "   macro avg       0.27      0.25      0.23        61\n",
      "weighted avg       0.41      0.48      0.41        61\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Model Support Vector Classification\n",
    "svc = SVC(kernel='rbf')\n",
    "svc.fit(x_train_scaled, y_train)\n",
    "\n",
    "y_pred_test_svc = svc.predict(x_test_scaled)\n",
    "print('Akurasi pada data test :',accuracy_score(y_test, y_pred_test_svc))\n",
    "print('Classification report  :\\n',classification_report(y_test, y_pred_test_svc))\n",
    "\n",
    "# Confusion matrix\n",
    "# print('Confusion matrix :\\n', confusion_matrix(y_test, y_pred_test_svc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Insight**\n",
    "- Akurasi: 47.5%\n",
    "- Meskipun sedikit lebih tinggi dibanding Logistic Regression, performa untuk kelas minoritas tetap kurang memadai.\n",
    "- Kesimpulan: SVC menunjukkan performa yang lebih baik pada kelas dominan, tetapi tidak menangani kelas minoritas dengan baik."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Kesimpulan Utama**\n",
    "- Overfitting menjadi masalah utama pada Random Forest, sedangkan model lain seperti Logistic Regression dan SVC mengalami kesulitan dalam menangani kelas minoritas.\n",
    "- AdaBoost menunjukkan performa yang lebih seimbang dibanding model lain, dengan akurasi yang lebih baik pada kelas minoritas, meskipun tidak spektakuler.\n",
    "- KNN dan SVC sedikit lebih baik dalam menangani data test dibanding Logistic Regression, tetapi masih belum optimal."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Model Terbaik**\n",
    "- Dari hasil ini, AdaBoost tampaknya menjadi model terbaik karena memberikan hasil yang paling seimbang antara data training dan data test, meskipun akurasi keseluruhannya tidak terlalu tinggi."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Resampling Data dengan SMOTE** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Akurasi pada data test : 0.4426229508196721\n",
      "Classification report  :\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.71      0.76      0.73        29\n",
      "           1       0.10      0.08      0.09        12\n",
      "           2       0.20      0.22      0.21         9\n",
      "           3       0.22      0.29      0.25         7\n",
      "           4       0.00      0.00      0.00         4\n",
      "\n",
      "    accuracy                           0.44        61\n",
      "   macro avg       0.25      0.27      0.26        61\n",
      "weighted avg       0.41      0.44      0.43        61\n",
      "\n",
      "Confusion matrix       :\n",
      " [[22  5  2  0  0]\n",
      " [ 5  1  2  4  0]\n",
      " [ 3  1  2  2  1]\n",
      " [ 1  2  2  2  0]\n",
      " [ 0  1  2  1  0]]\n"
     ]
    }
   ],
   "source": [
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "\n",
    "# SMOTE untuk menangani ketidakseimbangan data\n",
    "smote = SMOTE(random_state=42)\n",
    "x_train_resampled, y_train_resampled = smote.fit_resample(x_train_scaled, y_train)\n",
    "\n",
    "# AdaBoost model training\n",
    "ada = AdaBoostClassifier(n_estimators=100, random_state=42)\n",
    "ada.fit(x_train_resampled, y_train_resampled)\n",
    "\n",
    "# Prediksi pada data test\n",
    "y_pred_test_ada = ada.predict(x_test_scaled)\n",
    "\n",
    "# Evaluasi performa\n",
    "print('Akurasi pada data test :', accuracy_score(y_test, y_pred_test_ada))\n",
    "print('Classification report  :\\n', classification_report(y_test, y_pred_test_ada))\n",
    "print('Confusion matrix       :\\n', confusion_matrix(y_test, y_pred_test_ada))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Akurasi:\n",
    "- AdaBoost tanpa SMOTE: 52.46%\n",
    "- AdaBoost dengan SMOTE: 44.26%\n",
    "\n",
    "    Ada sedikit penurunan akurasi pada data test setelah menggunakan SMOTE. Ini bisa jadi karena penanganan ketidakseimbangan data dengan oversampling menyebabkan model belajar lebih banyak tentang kelas minoritas, yang membuat performanya pada kelas mayoritas (seperti kelas 0) sedikit menurun.\n",
    "\n",
    "Precision, Recall, dan F1-Score:\n",
    "\n",
    "- Kelas 0: Precision dan recall pada kelas 0 menurun sedikit setelah menggunakan SMOTE (dari 0.74/0.86 menjadi 0.71/0.76). Ini menunjukkan bahwa model sekarang tidak lagi terlalu mengutamakan kelas mayoritas.\n",
    "- Kelas minoritas (1, 2, 3, dan 4): Ada sedikit peningkatan pada beberapa kelas minoritas, terutama kelas 2 dan 3. Misalnya, recall untuk kelas 3 meningkat dari 0.17 menjadi 0.29, dan untuk kelas 2 meningkat dari 0.30 menjadi 0.22.\n",
    "\n",
    "    Namun, performa secara keseluruhan pada kelas minoritas masih rendah, karena f1-score untuk kelas 1, 2, 3, dan 4 tetap rendah. SMOTE membantu dengan memperbaiki recall untuk beberapa kelas, tetapi precision dan akurasi keseluruhan tetap belum optimal.\n",
    "\n",
    "**Insight:**\n",
    "- SMOTE: Meskipun SMOTE membantu menyeimbangkan distribusi data dengan menambahkan sampel dari kelas minoritas, hasilnya menunjukkan bahwa masalah ketidakseimbangan data bukan satu-satunya penyebab performa yang buruk. Model masih kesulitan mengenali kelas minoritas dengan baik, meskipun SMOTE telah meningkatkan representasi data.\n",
    "- AdaBoost: Algoritma AdaBoost sensitif terhadap outlier, dan ketika SMOTE menambahkan sampel sintetis, hal ini bisa mengganggu proses boosting. Ini mungkin salah satu alasan mengapa akurasi menurun setelah SMOTE diterapkan."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Balanced Random Forest - Akurasi pada data test: 0.5081967213114754\n",
      "Classification report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.76      0.83        29\n",
      "           1       0.42      0.42      0.42        12\n",
      "           2       0.09      0.11      0.10         9\n",
      "           3       0.22      0.29      0.25         7\n",
      "           4       0.20      0.25      0.22         4\n",
      "\n",
      "    accuracy                           0.51        61\n",
      "   macro avg       0.37      0.36      0.36        61\n",
      "weighted avg       0.57      0.51      0.53        61\n",
      "\n",
      "Confusion matrix:\n",
      " [[22  4  3  0  0]\n",
      " [ 1  5  2  2  2]\n",
      " [ 0  2  1  4  2]\n",
      " [ 1  0  4  2  0]\n",
      " [ 0  1  1  1  1]]\n"
     ]
    }
   ],
   "source": [
    "# Install library yang diperlukan\n",
    "# !pip install imbalanced-learn\n",
    "\n",
    "from imblearn.ensemble import BalancedRandomForestClassifier\n",
    "from sklearn.metrics import classification_report, accuracy_score, confusion_matrix\n",
    "\n",
    "# Inisiasi BalancedRandomForestClassifier\n",
    "brf = BalancedRandomForestClassifier(n_estimators=100, random_state=42)\n",
    "\n",
    "# Training pada data yang sudah discale tanpa SMOTE (BalancedRandomForest mengatasi ketidakseimbangan data)\n",
    "brf.fit(x_train_scaled, y_train)\n",
    "\n",
    "# Prediksi pada data test\n",
    "y_pred_test_brf = brf.predict(x_test_scaled)\n",
    "\n",
    "# Evaluasi performa\n",
    "print('Balanced Random Forest - Akurasi pada data test:', accuracy_score(y_test, y_pred_test_brf))\n",
    "print('Classification report:\\n', classification_report(y_test, y_pred_test_brf))\n",
    "print('Confusion matrix:\\n', confusion_matrix(y_test, y_pred_test_brf))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting xgboost\n",
      "  Downloading xgboost-2.1.1-py3-none-win_amd64.whl (124.9 MB)\n",
      "Requirement already satisfied: numpy in c:\\users\\wirad\\anaconda3\\lib\\site-packages (from xgboost) (1.26.1)\n",
      "Requirement already satisfied: scipy in c:\\users\\wirad\\anaconda3\\lib\\site-packages (from xgboost) (1.11.3)\n",
      "Installing collected packages: xgboost\n",
      "Successfully installed xgboost-2.1.1\n"
     ]
    }
   ],
   "source": [
    "!pip install xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGBoost - Akurasi pada data test: 0.47540983606557374\n",
      "Classification report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.74      0.86      0.79        29\n",
      "           1       0.00      0.00      0.00        12\n",
      "           2       0.33      0.33      0.33         9\n",
      "           3       0.09      0.14      0.11         7\n",
      "           4       0.00      0.00      0.00         4\n",
      "\n",
      "    accuracy                           0.48        61\n",
      "   macro avg       0.23      0.27      0.25        61\n",
      "weighted avg       0.41      0.48      0.44        61\n",
      "\n",
      "Confusion matrix:\n",
      " [[25  2  2  0  0]\n",
      " [ 6  0  1  5  0]\n",
      " [ 1  1  3  4  0]\n",
      " [ 2  2  2  1  0]\n",
      " [ 0  2  1  1  0]]\n"
     ]
    }
   ],
   "source": [
    "# Install library XGBoost\n",
    "# !pip install xgboost\n",
    "\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import classification_report, accuracy_score, confusion_matrix\n",
    "\n",
    "# Inisiasi XGBoostClassifier\n",
    "xgb = XGBClassifier(n_estimators=100, random_state=42, use_label_encoder=False, eval_metric='mlogloss')\n",
    "\n",
    "# Training pada data yang sudah discale\n",
    "xgb.fit(x_train_scaled, y_train)\n",
    "\n",
    "# Prediksi pada data test\n",
    "y_pred_test_xgb = xgb.predict(x_test_scaled)\n",
    "\n",
    "# Evaluasi performa\n",
    "print('XGBoost - Akurasi pada data test:', accuracy_score(y_test, y_pred_test_xgb))\n",
    "print('Classification report:\\n', classification_report(y_test, y_pred_test_xgb))\n",
    "print('Confusion matrix:\\n', confusion_matrix(y_test, y_pred_test_xgb))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
