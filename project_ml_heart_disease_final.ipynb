{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Pengantar\n",
    "\n",
    "Penyakit jantung adalah salah satu penyebab kematian utama di seluruh dunia. Deteksi dini penyakit ini menjadi penting untuk meningkatkan peluang perawatan yang efektif. Proyek ini berfokus pada prediksi penyakit jantung dengan memanfaatkan machine learning, yang bertujuan untuk membantu tenaga medis mengidentifikasi pasien dengan risiko tinggi terkena serangan jantung. Teknologi prediktif seperti ini berpotensi mengurangi biaya perawatan kesehatan dan menyelamatkan nyawa.\n",
    "\n",
    "Motivasi untuk menyelesaikan masalah ini muncul dari pentingnya menyediakan alat bantu yang cepat dan akurat bagi tenaga medis. Dengan menggunakan model machine learning, prediksi dapat dilakukan secara real-time berdasarkan berbagai faktor kesehatan pasien. Sebagai contoh, karakteristik seperti usia, jenis kelamin, tekanan darah, kadar kolesterol, dan variabel lainnya menjadi input bagi model.\n",
    "\n",
    "Input dari permasalahan ini adalah fitur-fitur klinis dari pasien, termasuk variabel seperti usia, jenis kelamin, tekanan darah, kadar kolesterol, detak jantung maksimal, dan lain-lain.\n",
    " \n",
    "Outputnya adalah prediksi apakah seseorang berisiko terkena penyakit jantung atau tidak. Dengan menggunakan berbagai algoritma machine learning seperti Logistic Regression, K-Nearest Neighbors (KNN), Random Forest, dan Support Vector Classifier (SVC), kita memprediksi probabilitas pasien terkena penyakit jantung.\n",
    "\n",
    "Proyek ini berbeda dari yang lain karena menggunakan pendekatan beragam model serta mengombinasikan beberapa teknik untuk mengatasi masalah ketidakseimbangan data. Beberapa algoritma seperti Balanced Random Forest juga digunakan untuk mengatasi tantangan tersebut.\n",
    "\n",
    "Tujuan akhir dari proyek ini adalah menemukan model yang memberikan performa prediksi terbaik dan robust pada data baru, sehingga dapat diimplementasikan dalam konteks dunia nyata untuk membantu dokter mengambil keputusan.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Related Work\n",
    "1. \"Enhancing Heart Disease Prediction Accuracy through Machine Learning Techniques and Optimization\"\n",
    "Makalah ini membahas penggunaan Logistic Regression, Random Forest, KNN, Naïve Bayes, Gradient Boosting, dan AdaBoost dengan optimasi grid search dan validasi silang. Link Makalah https://www.mdpi.com/2227-9717/11/4/1210\n",
    "2. \"Heart Disease Prediction Using Machine Learning Algorithms\"\n",
    "Menjelajahi Logistic Regression, Random Forest, SVC, dan KNN menggunakan dataset Cleveland. Link makalah https://www.researchgate.net/publication/341814860_Early_prediction_of_coronary_heart_disease_from_cleveland_dataset_using_machine_learning_techniques\n",
    "3. \"Prediction of Heart Disease using Machine Learning Algorithms\"\n",
    "Membandingkan Logistic Regression, KNN, Random Forest, dan SVM untuk prediksi penyakit jantung. Link makalah https://ieeexplore.ieee.org/document/8741465\n",
    "4. \"Performance Analysis of Machine Learning Algorithms for Heart Disease Prediction\"\n",
    "Membahas Random Forest, SVM, dan Logistic Regression yang diaplikasikan pada dataset Cleveland. Link makalah https://ieeexplore.ieee.org/document/10126428\n",
    "\n",
    "**Kategori**\n",
    "- Logistic Regression dan Metode Klasik: Makalah 1, 2, dan 3 menyoroti model klasik seperti Logistic Regression dan membandingkannya dengan Random Forest, KNN, dan SVC.\n",
    "- Model Ensemble (Random Forest, AdaBoost): Makalah 1 dan 4 menekankan pada model ensemble, terutama Random Forest dan AdaBoost.\n",
    "- Tuning Hyperparameter: Makalah 1 dan 3 berfokus pada metode tuning seperti GridSearchCV untuk mengoptimalkan performa.\n",
    "\n",
    "**Kelebihan dan kekurangan**\n",
    "- Kelebihan: Semua model menawarkan fleksibilitas dalam menangani dataset berbeda dan memberikan wawasan yang berarti tentang prediksi penyakit jantung. Random Forest dan AdaBoost cenderung menangani data yang tidak seimbang dengan baik dan memberikan performa yang kuat pada data terstruktur.\n",
    "- Kekurangan: Logistic Regression mungkin berkinerja kurang optimal pada data yang kompleks, sementara model ensemble seperti Random Forest dapat mengalami overfitting, terutama pada dataset yang lebih kecil. AdaBoost sensitif terhadap data outlier yang dapat menyebabkan penurunan kinerja.\n",
    "\n",
    "**Persamaan dan Perbedaan dengan Proyek ini**\n",
    "- Persamaan: Baik proyek saya maupun makalah-makalah ini menggunakan model yang serupa seperti Logistic Regression, Random Forest, AdaBoost, dan SVC. Saya juga menggunakan grid search untuk tuning hyperparameter, sama seperti banyak makalah yang disebutkan.\n",
    "- Perbedaan: Beberapa makalah menggunakan teknik ensemble tambahan seperti Gradient Boosting atau Soft Voting, yang mungkin bisa saya pertimbangkan. Metode evaluasi saya dan pilihan dataset juga mungkin berbeda, terutama dalam hal generalisasi model di berbagai dataset (Cleveland vs dataset lain).\n",
    "\n",
    "**Opini**\n",
    "\n",
    "Model-model yang saya gugnakan —Logistic Regression, Random Forest, KNN, AdaBoost, dan SVC— sesuai dengan pendekatan umum dalam prediksi penyakit jantung. Sebagian besar makalah menekankan pentingnya metode ensemble seperti Random Forest dan AdaBoost karena ketahanannya terhadap overfitting dan peningkatan generalisasi pada dataset medis yang terstruktur.\n",
    "\n",
    "Namun, integrasi metode voting ensemble dan teknik boosting tambahan, seperti yang ditunjukkan dalam beberapa makalah, dapat memberikan kinerja prediktif yang lebih baik. Selain itu, fokus pada tuning hyperparameter menggunakan cross-validation, seperti dalam studi-studi tersebut, kemungkinan akan meningkatkan keandalan dan performa model. Mengingat hasil yang beragam di berbagai dataset, tuning dan pengujian yang cermat sangat penting untuk memaksimalkan akurasi model pada project prediksi penyakit jantung."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Machine Learning Workflow\n",
    "\n",
    "### 1. Importing Data to Python\n",
    "* Drop Duplicates\n",
    "### 2. Data Preprocessing\n",
    "* Input-output Split\n",
    "* Train - Test Split\n",
    "* Imputation\n",
    "* Processing Categorical\n",
    "* Normalization\n",
    "### 3. Training Machine Learning\n",
    "* Choose Score to optimize and Hyperparameter Space"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Heart Disease Analysis**\n",
    "* Task : Classification\n",
    "* Objective : Prediksi pasien yang berpotensi kena serangan jantung"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Dataset & Features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dataset yang digunakan dalam proyek ini adalah Heart Disease Dataset yang diperoleh dari UCI Machine Learning Repository. Dataset ini terdiri dari 303 entri dan mencakup 14 fitur. Beberapa fitur utama yang digunakan adalah usia (age), jenis kelamin (sex), tekanan darah (trestbps), kolesterol (chol), hasil elektrokardiogram (restecg), detak jantung maksimum (thalach), dan angina yang diinduksi oleh latihan (exang).\n",
    "Link sources: https://archive.ics.uci.edu/dataset/45/heart+disease \n",
    "\n",
    "### Data Description\n",
    "**Informasi tambahan:**\n",
    "\n",
    "Database ini memiliki 76 atribut, namun semua eksperimen yang dipublikasikan hanya menggunakan subset dari 14 atribut tersebut. Secara khusus, database Cleveland adalah satu-satunya yang telah digunakan oleh peneliti machine learning hingga saat ini. Kolom \"target\" mengacu pada keberadaan penyakit jantung pada pasien, dengan nilai integer dari 0 (tidak ada penyakit) hingga 4 (kehadiran penyakit). Eksperimen yang dilakukan dengan database Cleveland berfokus pada usaha untuk membedakan antara keberadaan penyakit (nilai 1, 2, 3, 4) dengan tidak adanya penyakit (nilai 0).\n",
    "\n",
    "**Dataset Atribut**\n",
    "\n",
    "| Atribut    | Type         | Deskripsi                        |\n",
    "|------------|--------------|----------------------------------|\n",
    "| age        | Integer      | Usia pasien                      |\n",
    "| sex        | Categorical  | Jenis kelamin pasien *(0=wanita, 1=pria)*|\n",
    "| cp         | Categorical  | Tipe nyeri dada *(1=angina tipikal, 2=angina atipikal, 3=nyeri non-angina, 4=tanpa gejala)*             |\n",
    "| trestbps   | Integer      | Tekanan darah istirahat (mm Hg)  |\n",
    "| chol       | Integer      | Kolesterol serum (mg/dl)         |\n",
    "| fbs        | Categorical  | Gula darah puasa >120 mg/dl (1=benar, 0=salah)|\n",
    "| restecg    | Categorical  | Hasil elektrokardiografi istirahat *(0=normal, 1=memiliki kelainan gelombang ST-T (inversi gelombang T dan/atau elevasi atau depresi ST > 0,05 mV), 2=menunjukkan hipertrofi ventrikel kiri yang mungkin atau pasti berdasarkan kriteria Estes)*|\n",
    "| thalach    | Integer      | Denyut jantung max yang dicapai|\n",
    "| exang      | Categorical  | Angina yang disebabkan oleh olahraga *(1=ya, 0=tidak)*|\n",
    "| oldpeak    | Integer      | Depresi ST yang diinduksi oleh olahraga relatif terhadap istirahat|\n",
    "| slope      | Categorical  | Kemiringan segmen ST puncak latihan (0-2)|\n",
    "| ca         | Integer      | Jumlah pembuluh besar yang diwarnai oleh fluoroskopi (0-3)|\n",
    "| thal       | Categorical  | Thalassemia *(1 = normal; 2 = cacat tetap; 3 = cacat reversibel)*|\n",
    "| target     | Integer      | Diagnosa penyakit jantung *(0=tidak ada, 1-4=ada)*|\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Metode\n",
    "\n",
    "#### 4.1 Logistic Regression\n",
    "\n",
    "Metode: Logistic Regression digunakan untuk klasifikasi biner. Model ini memprediksi probabilitas suatu peristiwa terjadi, dengan batasan nilai antara 0 dan 1 menggunakan fungsi sigmoid.\n",
    "\n",
    "Notasi Matematis:\n",
    "$$\n",
    "P(y=1 \\mid X) = \\sigma(X\\beta) = \\frac{1}{1 + e^{-X\\beta}}\n",
    "$$\n",
    "\n",
    "- _X_: Fitur input\n",
    "- _β_: Koefisien regresi yang dipelajari\n",
    "- _σ(z)_: Fungsi sigmoid\n",
    "\n",
    "Algoritma: Model dioptimalkan menggunakan metode Maximum Likelihood Estimation (MLE), yang bertujuan untuk menemukan parameter yang memaksimalkan probabilitas mengamati data yang diberikan\n",
    "\n",
    "Cara Kerja: Logistic regression menggunakan turunan gradien untuk memperbarui parameter secara iteratif hingga ditemukan titik di mana loss function (negatif dari log-likelihood) mencapai minimum.\n",
    "\n",
    "#### 4.2 K-Nearest Neighbors (KNN)\n",
    "\n",
    "Metode: KNN adalah algoritma non-parametrik untuk klasifikasi yang bekerja berdasarkan jarak antara sampel.\n",
    "\n",
    "Notasi Matematis:\n",
    "- $d(x,x ′)$: Fungsi jarak, umumnya Euclidean distance:\n",
    "\n",
    "$$d(x, x') = \\sqrt{\\sum_{i=1}^{n} (x_i - x'_i)^2}$$\n",
    "\n",
    "Algoritma:\n",
    "\n",
    "- Hitung jarak antara data uji dengan semua data latih.\n",
    "- Pilih k tetangga terdekat.\n",
    "- Klasifikasi dilakukan berdasarkan mayoritas label dari tetangga terdekat.\n",
    "\n",
    "Cara Kerja: Algoritma menghitung jarak dari tiap data ke sampel uji, kemudian memprediksi berdasarkan suara terbanyak dari k tetangga terdekat.\n",
    "\n",
    "#### 4.3 Random Forest\n",
    "\n",
    "Metode: Random Forest adalah algoritma ensemble yang menggabungkan banyak decision trees untuk menghasilkan prediksi yang lebih akurat dan stabil.\n",
    "\n",
    "Notasi Matematis:\n",
    "\n",
    "- Setiap decision tree membagi data berdasarkan informasi gain atau Gini impurity. Gini impurity untuk node $j$ dihitung sebagai:\n",
    "\n",
    "$$ G(j) = 1 - \\sum_{k=1}^{K} p_k^2 $$\n",
    "\n",
    "- $p_k$ : Proporsi kelas $𝑘$ pada node tersebut\n",
    "\n",
    "Algoritma:\n",
    "\n",
    "- Buat banyak decision trees menggunakan bootstrap sampling.\n",
    "- Setiap pohon hanya menggunakan subset acak dari fitur.\n",
    "- Gabungkan prediksi semua pohon menggunakan majority vote (untuk klasifikasi) atau rata-rata (untuk regresi).\n",
    "\n",
    "Cara Kerja: Random Forest memitigasi overfitting yang sering terjadi pada single decision tree dengan mengombinasikan banyak pohon yang dilatih dari subset acak data dan fitur.\n",
    "\n",
    "#### 4.4 AdaBoost\n",
    "\n",
    "Metode: AdaBoost (Adaptive Boosting) adalah algoritma ensemble yang meningkatkan kinerja model lemah secara bertahap dengan memberikan bobot lebih besar pada data yang sulit diklasifikasikan\n",
    "\n",
    "Notasi Matematis:\n",
    "\n",
    "- Misalkan $ℎ_𝑡(x)$ adalah model dasar pada iterasi $𝑡$, maka total prediksi adalah:\n",
    "$$ H(x) = \\text{sign}\\left( \\sum_{t=1}^{T} \\alpha_t h_t(x) \\right) $$\n",
    "\n",
    "- $α_t$ : Bobot model dasar pada iterasi $𝑡$, yang dihitung berdasarkan error dari model tersebut\n",
    "\n",
    "Algoritma:\n",
    "\n",
    "- Latih model dasar pada data.\n",
    "- Hitung kesalahan dan perbarui bobot data.\n",
    "- Data yang salah diklasifikasikan diberi bobot lebih tinggi pada iterasi selanjutnya.\n",
    "\n",
    "Cara Kerja: AdaBoost melatih model lemah secara iteratif, memberi lebih banyak perhatian pada sampel yang salah diklasifikasikan, sehingga model selanjutnya fokus pada kesalahan dari model sebelumnya.\n",
    "\n",
    "#### 4.5 Support Vector Classifier (SVC)\n",
    "\n",
    "Metode: SVC bertujuan untuk menemukan hyperplane yang memisahkan kelas-kelas dalam ruang fitur dengan margin maksimum.\n",
    "\n",
    "Notasi Matematis:\n",
    "\n",
    "- Hyperplane didefinisikan sebagai $𝑤𝑇𝑥$+b=0, dengan margin dihitung sebagai:\n",
    "\n",
    "$$\\text{Margin} = \\frac{||w||}{2}$$\n",
    "\n",
    "Algoritma:\n",
    "\n",
    "1. Cari $w$ dan $𝑏$ yang memaksimalkan margin.\n",
    "2. Jika data tidak bisa dipisahkan secara linear, gunakan kernel trick untuk memetakan data ke dimensi yang lebih tinggi.\n",
    "\n",
    "Cara Kerja: SVC memisahkan data dengan margin maksimum, dan untuk data yang tidak terpisahkan secara linear, kernel (seperti RBF atau polynomial) digunakan untuk memetakan ke ruang fitur yang lebih tinggi agar dapat dipisahkan.\n",
    "​\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <b><font color='orange'> 1. Importing Data to Python </b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import library pengolahan struktur data\n",
    "import pandas as pd\n",
    "\n",
    "# Import library pengolahan angka\n",
    "import numpy as np\n",
    "\n",
    "# Import library untuk visualisasi\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Matikan peringatan agar tidak mengganggu output\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Buat fungsi untuk mengimpor dataset\n",
    "def ImportData(data_file):\n",
    "    \"\"\"\n",
    "    Fungsi untuk import data dan hapus duplikat jika ada.\n",
    "    :param data_file: <string> nama file input (format .data)\n",
    "    :return heart_df: <pandas> data yang telah diolah\n",
    "    \"\"\"\n",
    "    # Definisikan nama kolom sesuai dengan dokumentasi dataset\n",
    "    column_names = ['age', 'sex', 'cp', 'trestbps', 'chol', 'fbs', 'restecg', 'thalach', 'exang', 'oldpeak', 'slope', 'ca', 'thal', 'target']\n",
    "\n",
    "    # Baca data dengan pandas\n",
    "    heart_df = pd.read_csv(data_file, names=column_names)\n",
    "\n",
    "    # Cetak bentuk data asli\n",
    "    print('Data asli:',heart_df.shape, '-(#Observasi, #kolom)')\n",
    "    print('Jumlah baris',heart_df.shape[0], 'dan jumlah kolom',heart_df.shape[1])\n",
    "\n",
    "    # Cek apakah ada data duplikat\n",
    "    duplicate_status = heart_df.duplicated(keep='first')\n",
    "\n",
    "    # Jika ada duplikat, hapus dan tampilkan bentuk data setelah penghapusan\n",
    "    if duplicate_status.sum() == 0:\n",
    "        print('Tidak ada data duplikat')\n",
    "    else:\n",
    "        heart_df = heart_df.drop_duplicates()\n",
    "        print('Data setelah di-drop :', heart_df.shape, '-(#observasi, #kolom)')\n",
    "\n",
    "    return heart_df\n",
    "\n",
    "# (data_file) adalah argumen\n",
    "# Argumen adalah sebuah variable\n",
    "# Jika fungsi tersebut diberi argumen data_file = \"processed.cleveland.data\",\n",
    "# maka semua variable 'data_file' didalam fungsi akan berubah menjadi 'processed.cleveland.data'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data asli: (303, 14) -(#Observasi, #kolom)\n",
      "Jumlah baris 303 dan jumlah kolom 14\n",
      "Tidak ada data duplikat\n"
     ]
    }
   ],
   "source": [
    "# Argumen input\n",
    "data_file = 'processed.cleveland.data'\n",
    "\n",
    "# Panggil fungsi untuk mengimpor data\n",
    "heart_df = ImportData(data_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>cp</th>\n",
       "      <th>trestbps</th>\n",
       "      <th>chol</th>\n",
       "      <th>fbs</th>\n",
       "      <th>restecg</th>\n",
       "      <th>thalach</th>\n",
       "      <th>exang</th>\n",
       "      <th>oldpeak</th>\n",
       "      <th>slope</th>\n",
       "      <th>ca</th>\n",
       "      <th>thal</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>63.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>145.0</td>\n",
       "      <td>233.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>150.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.3</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>67.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>160.0</td>\n",
       "      <td>286.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>108.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.5</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>67.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>120.0</td>\n",
       "      <td>229.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>129.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.6</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>37.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>130.0</td>\n",
       "      <td>250.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>187.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>41.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>130.0</td>\n",
       "      <td>204.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>172.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    age  sex   cp  trestbps   chol  fbs  restecg  thalach  exang  oldpeak  \\\n",
       "0  63.0  1.0  1.0     145.0  233.0  1.0      2.0    150.0    0.0      2.3   \n",
       "1  67.0  1.0  4.0     160.0  286.0  0.0      2.0    108.0    1.0      1.5   \n",
       "2  67.0  1.0  4.0     120.0  229.0  0.0      2.0    129.0    1.0      2.6   \n",
       "3  37.0  1.0  3.0     130.0  250.0  0.0      0.0    187.0    0.0      3.5   \n",
       "4  41.0  0.0  2.0     130.0  204.0  0.0      2.0    172.0    0.0      1.4   \n",
       "\n",
       "   slope   ca thal  target  \n",
       "0    3.0  0.0  6.0       0  \n",
       "1    2.0  3.0  3.0       2  \n",
       "2    2.0  2.0  7.0       1  \n",
       "3    3.0  0.0  3.0       0  \n",
       "4    1.0  0.0  3.0       0  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Tampilkan 5 baris pertama data\n",
    "heart_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <b><font color='orange'> 2. Data Preprocessing:</font></b>\n",
    "---\n",
    "* Input-Output Split, Train-Test Split\n",
    "* Processing Categorical\n",
    "* Imputation, Normalization, Drop Duplicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Jumlah Nilai</th>\n",
       "      <th>Nilai Unik</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>age</th>\n",
       "      <td>41</td>\n",
       "      <td>[63.0, 67.0, 37.0, 41.0, 56.0, 62.0, 57.0, 53....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sex</th>\n",
       "      <td>2</td>\n",
       "      <td>[1.0, 0.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cp</th>\n",
       "      <td>4</td>\n",
       "      <td>[1.0, 4.0, 3.0, 2.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>trestbps</th>\n",
       "      <td>50</td>\n",
       "      <td>[145.0, 160.0, 120.0, 130.0, 140.0, 172.0, 150...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>chol</th>\n",
       "      <td>152</td>\n",
       "      <td>[233.0, 286.0, 229.0, 250.0, 204.0, 236.0, 268...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fbs</th>\n",
       "      <td>2</td>\n",
       "      <td>[1.0, 0.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>restecg</th>\n",
       "      <td>3</td>\n",
       "      <td>[2.0, 0.0, 1.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>thalach</th>\n",
       "      <td>91</td>\n",
       "      <td>[150.0, 108.0, 129.0, 187.0, 172.0, 178.0, 160...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>exang</th>\n",
       "      <td>2</td>\n",
       "      <td>[0.0, 1.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>oldpeak</th>\n",
       "      <td>40</td>\n",
       "      <td>[2.3, 1.5, 2.6, 3.5, 1.4, 0.8, 3.6, 0.6, 3.1, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>slope</th>\n",
       "      <td>3</td>\n",
       "      <td>[3.0, 2.0, 1.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ca</th>\n",
       "      <td>5</td>\n",
       "      <td>[0.0, 3.0, 2.0, 1.0, ?]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>thal</th>\n",
       "      <td>4</td>\n",
       "      <td>[6.0, 3.0, 7.0, ?]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>target</th>\n",
       "      <td>5</td>\n",
       "      <td>[0, 2, 1, 3, 4]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Jumlah Nilai                                         Nilai Unik\n",
       "age                41  [63.0, 67.0, 37.0, 41.0, 56.0, 62.0, 57.0, 53....\n",
       "sex                 2                                         [1.0, 0.0]\n",
       "cp                  4                               [1.0, 4.0, 3.0, 2.0]\n",
       "trestbps           50  [145.0, 160.0, 120.0, 130.0, 140.0, 172.0, 150...\n",
       "chol              152  [233.0, 286.0, 229.0, 250.0, 204.0, 236.0, 268...\n",
       "fbs                 2                                         [1.0, 0.0]\n",
       "restecg             3                                    [2.0, 0.0, 1.0]\n",
       "thalach            91  [150.0, 108.0, 129.0, 187.0, 172.0, 178.0, 160...\n",
       "exang               2                                         [0.0, 1.0]\n",
       "oldpeak            40  [2.3, 1.5, 2.6, 3.5, 1.4, 0.8, 3.6, 0.6, 3.1, ...\n",
       "slope               3                                    [3.0, 2.0, 1.0]\n",
       "ca                  5                            [0.0, 3.0, 2.0, 1.0, ?]\n",
       "thal                4                                 [6.0, 3.0, 7.0, ?]\n",
       "target              5                                    [0, 2, 1, 3, 4]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Cek Jumlah nilai dan nilai unik pada setip kolom\n",
    "summary_dict = {}\n",
    "for i in list(heart_df.columns):\n",
    "    # Buat dictionary untuk jumlah nilai dan nilai unik per kolom\n",
    "    summary_dict[i] = {\n",
    "        'Jumlah Nilai': heart_df[i].value_counts().shape[0],\n",
    "        'Nilai Unik': heart_df[i].unique()\n",
    "    }\n",
    "summary_df = pd.DataFrame(summary_dict).T\n",
    "\n",
    "# Tampilkan summary jumlah nilai dan nilai unik\n",
    "summary_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">Terdapat nilai **'?'** pada kolom `ca` dan `thal`. Kita perlu merubah nilai tersebut menjadi NA/NaN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Jumlah nilai \"?\" pada kolom ca   : 4\n",
      "Jumlah nilai \"?\" pada kolom thal : 2\n"
     ]
    }
   ],
   "source": [
    "# Terdapat nilai '?' pada kolom `ca` dan `thal`. Kita perlu mengganti nilai tersebut menjadi NaN\n",
    "print('Jumlah nilai \"?\" pada kolom ca   :', (heart_df['ca'] == '?').sum())\n",
    "print('Jumlah nilai \"?\" pada kolom thal :', (heart_df['thal'] == '?').sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>cp</th>\n",
       "      <th>trestbps</th>\n",
       "      <th>chol</th>\n",
       "      <th>fbs</th>\n",
       "      <th>restecg</th>\n",
       "      <th>thalach</th>\n",
       "      <th>exang</th>\n",
       "      <th>oldpeak</th>\n",
       "      <th>slope</th>\n",
       "      <th>ca</th>\n",
       "      <th>thal</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>87</th>\n",
       "      <td>53.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>128.0</td>\n",
       "      <td>216.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>115.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>?</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>166</th>\n",
       "      <td>52.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>138.0</td>\n",
       "      <td>223.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>169.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>?</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>192</th>\n",
       "      <td>43.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>132.0</td>\n",
       "      <td>247.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>143.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.1</td>\n",
       "      <td>2.0</td>\n",
       "      <td>?</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>266</th>\n",
       "      <td>52.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>128.0</td>\n",
       "      <td>204.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>156.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>?</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>287</th>\n",
       "      <td>58.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>125.0</td>\n",
       "      <td>220.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>144.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.4</td>\n",
       "      <td>2.0</td>\n",
       "      <td>?</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>302</th>\n",
       "      <td>38.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>138.0</td>\n",
       "      <td>175.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>173.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>?</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      age  sex   cp  trestbps   chol  fbs  restecg  thalach  exang  oldpeak  \\\n",
       "87   53.0  0.0  3.0     128.0  216.0  0.0      2.0    115.0    0.0      0.0   \n",
       "166  52.0  1.0  3.0     138.0  223.0  0.0      0.0    169.0    0.0      0.0   \n",
       "192  43.0  1.0  4.0     132.0  247.0  1.0      2.0    143.0    1.0      0.1   \n",
       "266  52.0  1.0  4.0     128.0  204.0  1.0      0.0    156.0    1.0      1.0   \n",
       "287  58.0  1.0  2.0     125.0  220.0  0.0      0.0    144.0    0.0      0.4   \n",
       "302  38.0  1.0  3.0     138.0  175.0  0.0      0.0    173.0    0.0      0.0   \n",
       "\n",
       "     slope   ca thal  target  \n",
       "87     1.0  0.0    ?       0  \n",
       "166    1.0    ?  3.0       0  \n",
       "192    2.0    ?  7.0       1  \n",
       "266    2.0  0.0    ?       2  \n",
       "287    2.0    ?  7.0       0  \n",
       "302    1.0    ?  3.0       0  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Lihat semua baris yang mengandung nilai '?'\n",
    "heart_df[heart_df.isin(['?']).any(axis=1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fungsi untuk menangani missing value\n",
    "def handle_missing_value(data):\n",
    "    \"\"\"\n",
    "    Fungsi untuk menangani missing value yang ditandai dengan '?'\n",
    "    param df: <pandas dataframe> data input\n",
    "    return df: <pandas dataframe> data dengan missing value yang sudah diganti\n",
    "    \"\"\"\n",
    "    \n",
    "    # Ganti '?' dengan NaN\n",
    "    data.replace('?', np.NaN, inplace=True)\n",
    "\n",
    "    # Tampilkan jumlah missing value per kolom\n",
    "    print('Jumlah missing value setelah dihapus:\\n', data.isnull().sum())\n",
    "\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Jumlah missing value setelah dihapus:\n",
      " age         0\n",
      "sex         0\n",
      "cp          0\n",
      "trestbps    0\n",
      "chol        0\n",
      "fbs         0\n",
      "restecg     0\n",
      "thalach     0\n",
      "exang       0\n",
      "oldpeak     0\n",
      "slope       0\n",
      "ca          4\n",
      "thal        2\n",
      "target      0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Panggil fungsi untuk menangai missing value\n",
    "heart_df = handle_missing_value(heart_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nilai unik kolom ca   : ['0.0' '3.0' '2.0' '1.0' nan]\n",
      "Nilai unik kolom thal : ['6.0' '3.0' '7.0' nan]\n"
     ]
    }
   ],
   "source": [
    "print('Nilai unik kolom ca   :', heart_df['ca'].unique())\n",
    "print('Nilai unik kolom thal :', heart_df['thal'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>cp</th>\n",
       "      <th>trestbps</th>\n",
       "      <th>chol</th>\n",
       "      <th>fbs</th>\n",
       "      <th>restecg</th>\n",
       "      <th>thalach</th>\n",
       "      <th>exang</th>\n",
       "      <th>oldpeak</th>\n",
       "      <th>slope</th>\n",
       "      <th>ca</th>\n",
       "      <th>thal</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>87</th>\n",
       "      <td>53.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>128.0</td>\n",
       "      <td>216.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>115.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>166</th>\n",
       "      <td>52.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>138.0</td>\n",
       "      <td>223.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>169.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>192</th>\n",
       "      <td>43.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>132.0</td>\n",
       "      <td>247.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>143.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.1</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>266</th>\n",
       "      <td>52.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>128.0</td>\n",
       "      <td>204.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>156.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>287</th>\n",
       "      <td>58.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>125.0</td>\n",
       "      <td>220.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>144.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.4</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>302</th>\n",
       "      <td>38.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>138.0</td>\n",
       "      <td>175.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>173.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      age  sex   cp  trestbps   chol  fbs  restecg  thalach  exang  oldpeak  \\\n",
       "87   53.0  0.0  3.0     128.0  216.0  0.0      2.0    115.0    0.0      0.0   \n",
       "166  52.0  1.0  3.0     138.0  223.0  0.0      0.0    169.0    0.0      0.0   \n",
       "192  43.0  1.0  4.0     132.0  247.0  1.0      2.0    143.0    1.0      0.1   \n",
       "266  52.0  1.0  4.0     128.0  204.0  1.0      0.0    156.0    1.0      1.0   \n",
       "287  58.0  1.0  2.0     125.0  220.0  0.0      0.0    144.0    0.0      0.4   \n",
       "302  38.0  1.0  3.0     138.0  175.0  0.0      0.0    173.0    0.0      0.0   \n",
       "\n",
       "     slope   ca thal  target  \n",
       "87     1.0  0.0  NaN       0  \n",
       "166    1.0  NaN  3.0       0  \n",
       "192    2.0  NaN  7.0       1  \n",
       "266    2.0  0.0  NaN       2  \n",
       "287    2.0  NaN  7.0       0  \n",
       "302    1.0  NaN  3.0       0  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Lihat semua baris yang mempunyai nilai NaN\n",
    "heart_df[heart_df.isna().any(axis=1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    " # Ganti missing value dengan string \"KOSONG\"\n",
    "fill_missing_value = heart_df.fillna(value=\"KOSONG\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>cp</th>\n",
       "      <th>trestbps</th>\n",
       "      <th>chol</th>\n",
       "      <th>fbs</th>\n",
       "      <th>restecg</th>\n",
       "      <th>thalach</th>\n",
       "      <th>exang</th>\n",
       "      <th>oldpeak</th>\n",
       "      <th>slope</th>\n",
       "      <th>ca</th>\n",
       "      <th>thal</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>87</th>\n",
       "      <td>53.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>128.0</td>\n",
       "      <td>216.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>115.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>KOSONG</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>166</th>\n",
       "      <td>52.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>138.0</td>\n",
       "      <td>223.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>169.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>KOSONG</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>192</th>\n",
       "      <td>43.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>132.0</td>\n",
       "      <td>247.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>143.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.1</td>\n",
       "      <td>2.0</td>\n",
       "      <td>KOSONG</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>266</th>\n",
       "      <td>52.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>128.0</td>\n",
       "      <td>204.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>156.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>KOSONG</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>287</th>\n",
       "      <td>58.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>125.0</td>\n",
       "      <td>220.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>144.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.4</td>\n",
       "      <td>2.0</td>\n",
       "      <td>KOSONG</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>302</th>\n",
       "      <td>38.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>138.0</td>\n",
       "      <td>175.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>173.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>KOSONG</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      age  sex   cp  trestbps   chol  fbs  restecg  thalach  exang  oldpeak  \\\n",
       "87   53.0  0.0  3.0     128.0  216.0  0.0      2.0    115.0    0.0      0.0   \n",
       "166  52.0  1.0  3.0     138.0  223.0  0.0      0.0    169.0    0.0      0.0   \n",
       "192  43.0  1.0  4.0     132.0  247.0  1.0      2.0    143.0    1.0      0.1   \n",
       "266  52.0  1.0  4.0     128.0  204.0  1.0      0.0    156.0    1.0      1.0   \n",
       "287  58.0  1.0  2.0     125.0  220.0  0.0      0.0    144.0    0.0      0.4   \n",
       "302  38.0  1.0  3.0     138.0  175.0  0.0      0.0    173.0    0.0      0.0   \n",
       "\n",
       "     slope      ca    thal  target  \n",
       "87     1.0     0.0  KOSONG       0  \n",
       "166    1.0  KOSONG     3.0       0  \n",
       "192    2.0  KOSONG     7.0       1  \n",
       "266    2.0     0.0  KOSONG       2  \n",
       "287    2.0  KOSONG     7.0       0  \n",
       "302    1.0  KOSONG     3.0       0  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "heart_df = fill_missing_value\n",
    "\n",
    "# Cek baris dengan nilai 'KOSONG\n",
    "heart_df[heart_df.isin([\"KOSONG\"]).any(axis=1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(303, 14)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Cek bentuk data\n",
    "heart_df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Processing Categorical**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['age', 'sex', 'cp', 'trestbps', 'chol', 'fbs', 'restecg', 'thalach',\n",
      "       'exang', 'oldpeak', 'slope', 'ca', 'thal', 'target'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "# Cek nama kolom dataset\n",
    "print(heart_df.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Bedakan antara data categorical dengan numerical**\n",
    "\n",
    "Data Categorical\n",
    "- sex\n",
    "- cp\n",
    "- fbs\n",
    "- restecg\n",
    "- exang\n",
    "- slope\n",
    "- thal\n",
    "\n",
    "Sisanya adalah numerical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pisahkan kolom data categorical dan numerical\n",
    "categorical_column = ['sex','cp','fbs','restecg','exang','slope','thal']\n",
    "\n",
    "numerical_column = ['age','trestbps','chol','thalach','oldpeak', 'target']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['sex', 'cp', 'fbs', 'restecg', 'exang', 'slope', 'thal']\n",
      "['age', 'trestbps', 'chol', 'thalach', 'oldpeak', 'target']\n"
     ]
    }
   ],
   "source": [
    "# Tampilkan kolom categorical dan numerical\n",
    "print(categorical_column)\n",
    "print(numerical_column)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ubah kolom categorical menjadi tipe 'object'\n",
    "heart_df[categorical_column] = heart_df[categorical_column].astype('object')\n",
    "\n",
    "# Lakukan One-Hot Encoding pada data categorical\n",
    "categorical_ohe = pd.get_dummies(heart_df[categorical_column], columns=categorical_column)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 303 entries, 0 to 302\n",
      "Data columns (total 20 columns):\n",
      " #   Column       Non-Null Count  Dtype\n",
      "---  ------       --------------  -----\n",
      " 0   sex_0.0      303 non-null    bool \n",
      " 1   sex_1.0      303 non-null    bool \n",
      " 2   cp_1.0       303 non-null    bool \n",
      " 3   cp_2.0       303 non-null    bool \n",
      " 4   cp_3.0       303 non-null    bool \n",
      " 5   cp_4.0       303 non-null    bool \n",
      " 6   fbs_0.0      303 non-null    bool \n",
      " 7   fbs_1.0      303 non-null    bool \n",
      " 8   restecg_0.0  303 non-null    bool \n",
      " 9   restecg_1.0  303 non-null    bool \n",
      " 10  restecg_2.0  303 non-null    bool \n",
      " 11  exang_0.0    303 non-null    bool \n",
      " 12  exang_1.0    303 non-null    bool \n",
      " 13  slope_1.0    303 non-null    bool \n",
      " 14  slope_2.0    303 non-null    bool \n",
      " 15  slope_3.0    303 non-null    bool \n",
      " 16  thal_3.0     303 non-null    bool \n",
      " 17  thal_6.0     303 non-null    bool \n",
      " 18  thal_7.0     303 non-null    bool \n",
      " 19  thal_KOSONG  303 non-null    bool \n",
      "dtypes: bool(20)\n",
      "memory usage: 6.0 KB\n"
     ]
    }
   ],
   "source": [
    "# Cek tipe data categorical\n",
    "categorical_ohe.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "ohe_columns = categorical_ohe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Join data Numerical dan Categorical**\n",
    "- Data numerik & kategorik harus digabungkan kembali\n",
    "- Penggabungan dengan `pd.concat`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gabungkan data numerik dan data kategorikal yang sudah di-encode\n",
    "heart_df_concat = pd.concat([heart_df[numerical_column], categorical_ohe], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>trestbps</th>\n",
       "      <th>chol</th>\n",
       "      <th>thalach</th>\n",
       "      <th>oldpeak</th>\n",
       "      <th>target</th>\n",
       "      <th>sex_0.0</th>\n",
       "      <th>sex_1.0</th>\n",
       "      <th>cp_1.0</th>\n",
       "      <th>cp_2.0</th>\n",
       "      <th>...</th>\n",
       "      <th>restecg_2.0</th>\n",
       "      <th>exang_0.0</th>\n",
       "      <th>exang_1.0</th>\n",
       "      <th>slope_1.0</th>\n",
       "      <th>slope_2.0</th>\n",
       "      <th>slope_3.0</th>\n",
       "      <th>thal_3.0</th>\n",
       "      <th>thal_6.0</th>\n",
       "      <th>thal_7.0</th>\n",
       "      <th>thal_KOSONG</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>63.0</td>\n",
       "      <td>145.0</td>\n",
       "      <td>233.0</td>\n",
       "      <td>150.0</td>\n",
       "      <td>2.3</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>67.0</td>\n",
       "      <td>160.0</td>\n",
       "      <td>286.0</td>\n",
       "      <td>108.0</td>\n",
       "      <td>1.5</td>\n",
       "      <td>2</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>67.0</td>\n",
       "      <td>120.0</td>\n",
       "      <td>229.0</td>\n",
       "      <td>129.0</td>\n",
       "      <td>2.6</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>37.0</td>\n",
       "      <td>130.0</td>\n",
       "      <td>250.0</td>\n",
       "      <td>187.0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>41.0</td>\n",
       "      <td>130.0</td>\n",
       "      <td>204.0</td>\n",
       "      <td>172.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>...</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 26 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    age  trestbps   chol  thalach  oldpeak  target  sex_0.0  sex_1.0  cp_1.0  \\\n",
       "0  63.0     145.0  233.0    150.0      2.3       0    False     True    True   \n",
       "1  67.0     160.0  286.0    108.0      1.5       2    False     True   False   \n",
       "2  67.0     120.0  229.0    129.0      2.6       1    False     True   False   \n",
       "3  37.0     130.0  250.0    187.0      3.5       0    False     True   False   \n",
       "4  41.0     130.0  204.0    172.0      1.4       0     True    False   False   \n",
       "\n",
       "   cp_2.0  ...  restecg_2.0  exang_0.0  exang_1.0  slope_1.0  slope_2.0  \\\n",
       "0   False  ...         True       True      False      False      False   \n",
       "1   False  ...         True      False       True      False       True   \n",
       "2   False  ...         True      False       True      False       True   \n",
       "3   False  ...        False       True      False      False      False   \n",
       "4    True  ...         True       True      False       True      False   \n",
       "\n",
       "   slope_3.0  thal_3.0  thal_6.0  thal_7.0  thal_KOSONG  \n",
       "0       True     False      True     False        False  \n",
       "1      False      True     False     False        False  \n",
       "2      False     False     False      True        False  \n",
       "3       True      True     False     False        False  \n",
       "4      False      True     False     False        False  \n",
       "\n",
       "[5 rows x 26 columns]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Tampilkan hasil penggabungan\n",
    "heart_df_concat.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['age', 'trestbps', 'chol', 'thalach', 'oldpeak', 'target', 'sex_0.0',\n",
      "       'sex_1.0', 'cp_1.0', 'cp_2.0', 'cp_3.0', 'cp_4.0', 'fbs_0.0', 'fbs_1.0',\n",
      "       'restecg_0.0', 'restecg_1.0', 'restecg_2.0', 'exang_0.0', 'exang_1.0',\n",
      "       'slope_1.0', 'slope_2.0', 'slope_3.0', 'thal_3.0', 'thal_6.0',\n",
      "       'thal_7.0', 'thal_KOSONG'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "# Tampilkan kolom hasil penggabungan\n",
    "print(heart_df_concat.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Jumlah missing value hasil penggabungan data numerik & kategorik: 0\n"
     ]
    }
   ],
   "source": [
    "# Cek apakah ada missing value setelah penggabungan\n",
    "print(f\"Jumlah missing value hasil penggabungan data numerik & kategorik: {heart_df_concat.isnull().any().sum()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Input-Output Split**\n",
    "\n",
    "- Fitur `y` adalah output variabel yaitu kolom 'target'\n",
    "- Fitur `x` adalah input variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extractInputOutput(data, output_column_name):\n",
    "    \"\"\"\n",
    "    Fungsi untuk memisahkan data input dan output\n",
    "    :param data: <pandas dataframe> data seluruh sample\n",
    "    :param output_column_name: <string> nama kolom output\n",
    "    :return input_data: <pandas dataframe> data input\n",
    "    :return output_data: <pandas series> data output\n",
    "    \"\"\"\n",
    "   \n",
    "    # pisahkan data output\n",
    "    output_data = data[output_column_name]\n",
    "    \n",
    "    # drop kolom output dari data untuk mendapatkan input_data\n",
    "    input_data = data.drop(columns=output_column_name, axis=1)\n",
    "\n",
    "    return input_data, output_data\n",
    "\n",
    "# (data, output_column_name) adalah argumen\n",
    "# Argumen adalah sebuah variable\n",
    "# Jika fungsi tsb diberi argumen data = heart_df\n",
    "# maka semua variable 'data' didalam fungsi akan berubah menjadi heart_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Jalankan fungsi untuk memisahkan input-output\n",
    "x, y = extractInputOutput(heart_df_concat, output_column_name='target')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Jumlah missing value variable input: 0\n",
      "Jumlah missing value variable output: 0\n"
     ]
    }
   ],
   "source": [
    "# Cek apakah ada missing value di data input dan output\n",
    "print(f\"Jumlah missing value variable input: {x.isnull().any().sum()}\")\n",
    "print(f\"Jumlah missing value variable output: {y.isnull().any().sum()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Train-Test Split**\n",
    "- **Kenapa?**\n",
    "    - Karena tidak ingin overfit data training\n",
    "    - Test data akan menjadi future data\n",
    "    - Kita akan melatih model ML di data training dengan CV (Cross Validation)\n",
    "    - Selanjutnya melakukan evaluasi di data testing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Train Test Split Function**\n",
    "1. `X` adalah input\n",
    "2. `y` adalah output (target)\n",
    "3. `test_size` adalah seberapa besar proporsi data test dari keseluruhan data. Contoh `test_size = 0.2` artinya data test akan berisi 20% data.\n",
    "4. `random_state` adalah kunci untuk random. Harus di-setting sama. Misal `random_state = 123`.\n",
    "5. Output:\n",
    "   - `x_train` = input dari data training\n",
    "   - `x_test` = input dari data testing\n",
    "   - `y_train` = output dari data training\n",
    "   - `y_test` = output dari data testing\n",
    "6. Urutan outputnya: `x_train, x_test, y_train, y_test`. Tidak boleh terbalik\n",
    "\n",
    "> Readmore: https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.train_test_split.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import train-test splitting library dari sklearn\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Lakukan train-test split dengan test size 20%\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2,\n",
    "                                                    random_state=123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bentuk x_train (242, 25)\n",
      "Bentuk x_test  (61, 25)\n",
      "Bentuk y_train (242,)\n",
      "Bentuk y_test  (61,)\n"
     ]
    }
   ],
   "source": [
    "# Cek bentuk data setelah split\n",
    "print('Bentuk x_train', x_train.shape)\n",
    "print('Bentuk x_test ', x_test.shape)\n",
    "print('Bentuk y_train', y_train.shape)\n",
    "print('Bentuk y_test ',y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Jumlah kolom di x_train: 25\n",
      "Jumlah kolom di x_test: 25\n"
     ]
    }
   ],
   "source": [
    "# Cek apakah jumlah kolom di x_train dan x_test sama\n",
    "print(f\"Jumlah kolom di x_train: {x_train.shape[1]}\")\n",
    "print(f\"Jumlah kolom di x_test: {x_test.shape[1]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Jumlah missing value di variable input x_train : 0\n",
      "Jumlah missing value di variable output y_train: 0\n"
     ]
    }
   ],
   "source": [
    "# Cek missing value di x_train dan y_train\n",
    "print(f\"Jumlah missing value di variable input x_train : {x_train.isnull().any().sum()}\") \n",
    "print(f\"Jumlah missing value di variable output y_train: {y_train.isnull().any().sum()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Standardizing Variables\n",
    "- Menyamakan skala dari variable input\n",
    "- `fit` : imputer agar mengetahui mean dan standar deviasi dari setiap kolom\n",
    "- `transform` : isi data dengan value yang sudah di normalisasi\n",
    "- output dari transform berupa pandas dataframe\n",
    "- normalize dikeluarkan karena akan digunakan pada data test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import library untuk melakukan scaling\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "\n",
    "# Inisialisasi RobustScaler\n",
    "scaler = RobustScaler()\n",
    "\n",
    "# Lakukan fit-transform pada x_train dan simpan hasilnya dalam DataFrame baru\n",
    "x_train_scaled = pd.DataFrame(scaler.fit_transform(x_train), columns=x_train.columns, index=x_train.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>trestbps</th>\n",
       "      <th>chol</th>\n",
       "      <th>thalach</th>\n",
       "      <th>oldpeak</th>\n",
       "      <th>sex_0.0</th>\n",
       "      <th>sex_1.0</th>\n",
       "      <th>cp_1.0</th>\n",
       "      <th>cp_2.0</th>\n",
       "      <th>cp_3.0</th>\n",
       "      <th>...</th>\n",
       "      <th>restecg_2.0</th>\n",
       "      <th>exang_0.0</th>\n",
       "      <th>exang_1.0</th>\n",
       "      <th>slope_1.0</th>\n",
       "      <th>slope_2.0</th>\n",
       "      <th>slope_3.0</th>\n",
       "      <th>thal_3.0</th>\n",
       "      <th>thal_6.0</th>\n",
       "      <th>thal_7.0</th>\n",
       "      <th>thal_KOSONG</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>102</th>\n",
       "      <td>0.166667</td>\n",
       "      <td>-0.1</td>\n",
       "      <td>1.012146</td>\n",
       "      <td>0.162602</td>\n",
       "      <td>-0.500</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>261</th>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.3</td>\n",
       "      <td>1.271255</td>\n",
       "      <td>-0.065041</td>\n",
       "      <td>-0.500</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>228</th>\n",
       "      <td>-0.083333</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-0.558704</td>\n",
       "      <td>-1.495935</td>\n",
       "      <td>-0.500</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>288</th>\n",
       "      <td>0.083333</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.315789</td>\n",
       "      <td>0.292683</td>\n",
       "      <td>-0.500</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78</th>\n",
       "      <td>-0.583333</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.072874</td>\n",
       "      <td>0.845528</td>\n",
       "      <td>-0.375</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 25 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          age  trestbps      chol   thalach  oldpeak  sex_0.0  sex_1.0  \\\n",
       "102  0.166667      -0.1  1.012146  0.162602   -0.500      1.0     -1.0   \n",
       "261  0.250000       0.3  1.271255 -0.065041   -0.500      1.0     -1.0   \n",
       "228 -0.083333      -1.0 -0.558704 -1.495935   -0.500      0.0      0.0   \n",
       "288  0.083333       0.0 -0.315789  0.292683   -0.500      0.0      0.0   \n",
       "78  -0.583333       0.0  0.072874  0.845528   -0.375      0.0      0.0   \n",
       "\n",
       "     cp_1.0  cp_2.0  cp_3.0  ...  restecg_2.0  exang_0.0  exang_1.0  \\\n",
       "102     0.0     0.0     0.0  ...          0.0        0.0        0.0   \n",
       "261     0.0     1.0     0.0  ...          0.0        0.0        0.0   \n",
       "228     0.0     0.0     0.0  ...          0.0       -1.0        1.0   \n",
       "288     0.0     1.0     0.0  ...          0.0        0.0        0.0   \n",
       "78      0.0     1.0     0.0  ...          0.0        0.0        0.0   \n",
       "\n",
       "     slope_1.0  slope_2.0  slope_3.0  thal_3.0  thal_6.0  thal_7.0  \\\n",
       "102        1.0        0.0        0.0       0.0       0.0       0.0   \n",
       "261        1.0        0.0        0.0       0.0       0.0       0.0   \n",
       "228        0.0        1.0        0.0       0.0       0.0       0.0   \n",
       "288        1.0        0.0        0.0      -1.0       0.0       1.0   \n",
       "78         0.0        1.0        0.0       0.0       0.0       0.0   \n",
       "\n",
       "     thal_KOSONG  \n",
       "102          0.0  \n",
       "261          0.0  \n",
       "228          0.0  \n",
       "288          0.0  \n",
       "78           0.0  \n",
       "\n",
       "[5 rows x 25 columns]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Tampilkan 5 baris pertama hasil scaling\n",
    "x_train_scaled.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <b><font color='orange'> 3. Training Machine Learning:</font></b>\n",
    "---\n",
    "        - Kita harus mengalahkan benchmark"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Benchmark / Baseline**\n",
    "- Baseline untuk evaluasi nanti\n",
    "- Karena ini klarifikasi, bisa kita ambil dari proporsi kelas target yang terbesar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "target\n",
       "0    0.541322\n",
       "1    0.169421\n",
       "3    0.119835\n",
       "2    0.115702\n",
       "4    0.053719\n",
       "Name: proportion, dtype: float64"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Tampilkan benchmark distribusi kelas target\n",
    "benchmark = y_train.value_counts(normalize=True)\n",
    "benchmark"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Import Model\n",
    "- Kita akan gunakan 5 model Machine Learning:\n",
    "    - K-nearest neighbor (K-NN)\n",
    "    - Logistic Regression\n",
    "    - Random Forest\n",
    "    - Adaboost\n",
    "    - SVC\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import model dari sklearn\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.model_selection import RandomizedSearchCV, GridSearchCV\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Fitting Model, Cek Performa & Prediksi\n",
    "- Cara fitting / training model mengikuti yang dokumentasi model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model_on_train(model, x_train, y_train):\n",
    "    \"\"\"\n",
    "    Fungsi untuk melatih model, melakukan prediksi dan mengevaluasi performa model pada data training\n",
    "    :param model: <sklearn model object> model yang akan dilatih dan dievaluasi\n",
    "    :param x_train: <pandas dataframe or numpy array> data input untuk training yang sudah di fit-transform\n",
    "    :param y_train: <pandas dataframe or numpy array> data target/output untuk training\n",
    "    :return: Tidak ada nilai yang dikembalikan. Fungsi ini hanya mencetak akurasi dan classification report\n",
    "    \"\"\"\n",
    "    # Latih model pada data training\n",
    "    model.fit(x_train, y_train)\n",
    "\n",
    "    # Prediksi hasil pada data training\n",
    "    y_pred_train = model.predict(x_train)\n",
    "\n",
    "    # Evaluasi performa model\n",
    "    print(f'{model} - Akurasi pada data training    :', accuracy_score(y_train, y_pred_train))\n",
    "    # print('Classification report:\\n', classification_report(y_train, y_pred_train))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Test Prediction\n",
    "1. Siapkan file test dataset\n",
    "2. Lakukan preprocessing yang sama dengan yang dilakukan di train dataset\n",
    "3. Gunakan `imputer_numerical` jika ada data yang kosong dan `scaler` yang telah di fit di train dataset\n",
    "4. Lakukan hanya transform pada test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>trestbps</th>\n",
       "      <th>chol</th>\n",
       "      <th>thalach</th>\n",
       "      <th>oldpeak</th>\n",
       "      <th>sex_0.0</th>\n",
       "      <th>sex_1.0</th>\n",
       "      <th>cp_1.0</th>\n",
       "      <th>cp_2.0</th>\n",
       "      <th>cp_3.0</th>\n",
       "      <th>...</th>\n",
       "      <th>restecg_2.0</th>\n",
       "      <th>exang_0.0</th>\n",
       "      <th>exang_1.0</th>\n",
       "      <th>slope_1.0</th>\n",
       "      <th>slope_2.0</th>\n",
       "      <th>slope_3.0</th>\n",
       "      <th>thal_3.0</th>\n",
       "      <th>thal_6.0</th>\n",
       "      <th>thal_7.0</th>\n",
       "      <th>thal_KOSONG</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>56.0</td>\n",
       "      <td>140.0</td>\n",
       "      <td>294.0</td>\n",
       "      <td>153.0</td>\n",
       "      <td>1.3</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>292</th>\n",
       "      <td>44.0</td>\n",
       "      <td>120.0</td>\n",
       "      <td>169.0</td>\n",
       "      <td>144.0</td>\n",
       "      <td>2.8</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>269</th>\n",
       "      <td>42.0</td>\n",
       "      <td>130.0</td>\n",
       "      <td>180.0</td>\n",
       "      <td>150.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>268</th>\n",
       "      <td>40.0</td>\n",
       "      <td>152.0</td>\n",
       "      <td>223.0</td>\n",
       "      <td>181.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94</th>\n",
       "      <td>63.0</td>\n",
       "      <td>135.0</td>\n",
       "      <td>252.0</td>\n",
       "      <td>172.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>...</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 25 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      age  trestbps   chol  thalach  oldpeak  sex_0.0  sex_1.0  cp_1.0  \\\n",
       "11   56.0     140.0  294.0    153.0      1.3     True    False   False   \n",
       "292  44.0     120.0  169.0    144.0      2.8    False     True   False   \n",
       "269  42.0     130.0  180.0    150.0      0.0    False     True   False   \n",
       "268  40.0     152.0  223.0    181.0      0.0    False     True   False   \n",
       "94   63.0     135.0  252.0    172.0      0.0     True    False   False   \n",
       "\n",
       "     cp_2.0  cp_3.0  ...  restecg_2.0  exang_0.0  exang_1.0  slope_1.0  \\\n",
       "11     True   False  ...         True       True      False      False   \n",
       "292   False   False  ...        False      False       True      False   \n",
       "269   False    True  ...        False       True      False       True   \n",
       "268   False   False  ...        False       True      False       True   \n",
       "94    False    True  ...         True       True      False       True   \n",
       "\n",
       "     slope_2.0  slope_3.0  thal_3.0  thal_6.0  thal_7.0  thal_KOSONG  \n",
       "11        True      False      True     False     False        False  \n",
       "292      False       True     False      True     False        False  \n",
       "269      False      False      True     False     False        False  \n",
       "268      False      False     False     False      True        False  \n",
       "94       False      False      True     False     False        False  \n",
       "\n",
       "[5 rows x 25 columns]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Tampilkan 5 baris pertama data test\n",
    "x_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lakukan transform pada x_test dan simpan hasilnya dalam DataFrame baru\n",
    "x_test_scaled = pd.DataFrame(scaler.transform(x_test),columns=x_test.columns, index=x_test.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>trestbps</th>\n",
       "      <th>chol</th>\n",
       "      <th>thalach</th>\n",
       "      <th>oldpeak</th>\n",
       "      <th>sex_0.0</th>\n",
       "      <th>sex_1.0</th>\n",
       "      <th>cp_1.0</th>\n",
       "      <th>cp_2.0</th>\n",
       "      <th>cp_3.0</th>\n",
       "      <th>...</th>\n",
       "      <th>restecg_2.0</th>\n",
       "      <th>exang_0.0</th>\n",
       "      <th>exang_1.0</th>\n",
       "      <th>slope_1.0</th>\n",
       "      <th>slope_2.0</th>\n",
       "      <th>slope_3.0</th>\n",
       "      <th>thal_3.0</th>\n",
       "      <th>thal_6.0</th>\n",
       "      <th>thal_7.0</th>\n",
       "      <th>thal_KOSONG</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.083333</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.866397</td>\n",
       "      <td>-0.032520</td>\n",
       "      <td>0.3125</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>292</th>\n",
       "      <td>-0.916667</td>\n",
       "      <td>-0.50</td>\n",
       "      <td>-1.157895</td>\n",
       "      <td>-0.325203</td>\n",
       "      <td>1.2500</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>269</th>\n",
       "      <td>-1.083333</td>\n",
       "      <td>0.00</td>\n",
       "      <td>-0.979757</td>\n",
       "      <td>-0.130081</td>\n",
       "      <td>-0.5000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>268</th>\n",
       "      <td>-1.250000</td>\n",
       "      <td>1.10</td>\n",
       "      <td>-0.283401</td>\n",
       "      <td>0.878049</td>\n",
       "      <td>-0.5000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94</th>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.186235</td>\n",
       "      <td>0.585366</td>\n",
       "      <td>-0.5000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 25 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          age  trestbps      chol   thalach  oldpeak  sex_0.0  sex_1.0  \\\n",
       "11   0.083333      0.50  0.866397 -0.032520   0.3125      1.0     -1.0   \n",
       "292 -0.916667     -0.50 -1.157895 -0.325203   1.2500      0.0      0.0   \n",
       "269 -1.083333      0.00 -0.979757 -0.130081  -0.5000      0.0      0.0   \n",
       "268 -1.250000      1.10 -0.283401  0.878049  -0.5000      0.0      0.0   \n",
       "94   0.666667      0.25  0.186235  0.585366  -0.5000      1.0     -1.0   \n",
       "\n",
       "     cp_1.0  cp_2.0  cp_3.0  ...  restecg_2.0  exang_0.0  exang_1.0  \\\n",
       "11      0.0     1.0     0.0  ...          0.0        0.0        0.0   \n",
       "292     0.0     0.0     0.0  ...         -1.0       -1.0        1.0   \n",
       "269     0.0     0.0     1.0  ...         -1.0        0.0        0.0   \n",
       "268     0.0     0.0     0.0  ...         -1.0        0.0        0.0   \n",
       "94      0.0     0.0     1.0  ...          0.0        0.0        0.0   \n",
       "\n",
       "     slope_1.0  slope_2.0  slope_3.0  thal_3.0  thal_6.0  thal_7.0  \\\n",
       "11         0.0        1.0        0.0       0.0       0.0       0.0   \n",
       "292        0.0        0.0        1.0      -1.0       1.0       0.0   \n",
       "269        1.0        0.0        0.0       0.0       0.0       0.0   \n",
       "268        1.0        0.0        0.0      -1.0       0.0       1.0   \n",
       "94         1.0        0.0        0.0       0.0       0.0       0.0   \n",
       "\n",
       "     thal_KOSONG  \n",
       "11           0.0  \n",
       "292          0.0  \n",
       "269          0.0  \n",
       "268          0.0  \n",
       "94           0.0  \n",
       "\n",
       "[5 rows x 25 columns]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Tampilkan 5 baris pertama hasil transformm data test\n",
    "x_test_scaled.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Buat fungsi untuk mengevaluasi performa model pada data test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model_on_test(model, x_test, y_test):\n",
    "    \"\"\"\n",
    "    Fungsi untuk mengevaluasi performa model pada data test\n",
    "    :param model: <sklearn model object> model yang sudah dilatih\n",
    "    :param x_test: <pandas dataframe or numpy array> data input yang untuk testing (data test yang sudah discaling/transform)\n",
    "    :param y_test: <pandas series or numpy array> data target/output untuk testing\n",
    "    :return: Tidak ada nilai yang dikembalikan. Fungsi ini hanya mencetak akurasi dan classification report\n",
    "    \"\"\"\n",
    "    # Prediksi hasil pada data test\n",
    "    y_pred_test = model.predict(x_test) # Menggunakan data test yang diberikan ke fungsi\n",
    "\n",
    "    # Evaluasi performa model pada data test\n",
    "    print(f'{model} - Akurasi pada data test        :', accuracy_score(y_test, y_pred_test))\n",
    "    # print('Classification report:\\n', classification_report(y_test, y_pred_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Meningkatkan Performa Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Buat fungsi untuk mengevaluasi hyperparameter tuning dengan GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_grid_tuning_on_test(model, param_grid, x_train, y_train, x_test, y_test, cv=5, scoring='accuracy'):\n",
    "    \"\"\"\n",
    "    Fungsi untuk melakukan hyperparameter tuning dengan GridSearchCV pada model, melatih model terbaik\n",
    "    dan mengevaluasi paa data test\n",
    "    :param model: <sklearn model object> Model yang akan digunakan tuning hyperparameternya\n",
    "    :param param_grid: <dict> Parameter grid untuk tuning hyperparameter\n",
    "    :param x_train: <pandas dataframe or numpy array> Data input untuk training\n",
    "    :param y_train: <pandas dataframe or numpy array> Data output untuk training\n",
    "    :param x_test: <pandas dataframe or numpy array> Data input untuk testing\n",
    "    :param y_test: <pandas dataframe or numpy array> Data output untuk testing\n",
    "    :param cv: <int> Jumlah cross-validation folds (default: 5)\n",
    "    :param scoring: <str> Mertics untuk evaluasi model (default: 'accuracy')\n",
    "    :return: Tidak ada nilai yang dikembalikan. Fungsi ini akan mencetak hasil tuning, akurasi, dan classification report.\n",
    "    \"\"\"\n",
    "    # Melakukan GridSearchCV untuk hyperparameter tuning\n",
    "    grid_search = GridSearchCV(model, param_grid=param_grid, cv=cv, scoring=scoring)\n",
    "\n",
    "    # Latih model pada data training dengan parameter terbaik\n",
    "    grid_search.fit(x_train, y_train)\n",
    "\n",
    "    # Menampilkan hyperparameter terbaik dan akurasi pada data training\n",
    "    print(f'{model} - Best param for GridSearchCV   :', grid_search.best_params_)\n",
    "    print(f'{model} - Best accuracy on Training data:', grid_search.best_score_)\n",
    "\n",
    "    # Melakukan prediksi pada data test menggunakan model dengan parameter terbaik\n",
    "    best_model = grid_search.best_estimator_\n",
    "    y_pred_test = best_model.predict(x_test)\n",
    "\n",
    "    # Melakukan akurasi dan classification report pada data test\n",
    "    print(f'\\n{model} - Akurasi pada data test        :', accuracy_score(y_test, y_pred_test))\n",
    "    print('Classification report:\\n', classification_report(y_test, y_pred_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Buat fungsi untuk mengevaluasi hyperparameter tuning dengan RandomizedSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_randomized_tuning_on_test(model, param_distributions, x_train, y_train, x_test, y_test, \n",
    "                                       cv=5, scoring='accuracy', n_iter=10, random_state=123):\n",
    "    \"\"\"\n",
    "    Fungsi untuk melakukan hyperparameter tuning dengan RandomizedSearchCV pada model, melatih model terbaik,\n",
    "    dan mengevaluasinya pada data test.\n",
    "    :param model: <scikit-learn model object> Model yang akan dilakukan tuning hyperparameternya.\n",
    "    :param param_distributions: <dict> Distribusi parameter untuk tuning hyperparameter.\n",
    "    :param x_train: <pandas dataframe or numpy array> Data input untuk training.\n",
    "    :param y_train: <pandas series or numpy array> Data target untuk training.\n",
    "    :param x_test: <pandas dataframe or numpy array> Data input untuk testing.\n",
    "    :param y_test: <pandas series or numpy array> Data target untuk testing.\n",
    "    :param cv: <int> Jumlah cross-validation folds (default: 5).\n",
    "    :param scoring: <str> Metrik untuk evaluasi model (default: 'accuracy').\n",
    "    :param n_iter: <int> Jumlah iterasi untuk RandomizedSearchCV (default: 10).\n",
    "    :param random_state: <int> Seed untuk random state (default: 123).\n",
    "    \n",
    "    :return: Tidak ada nilai yang dikembalikan. Fungsi ini akan mencetak hasil tuning, akurasi, dan classification report.\n",
    "    \"\"\"\n",
    "    # Melakukan RandomizedSearchCV untuk hyperparameter tuning\n",
    "    randomized_search = RandomizedSearchCV(model, param_distributions=param_distributions, cv=cv, \n",
    "                                           scoring=scoring, n_iter=n_iter, random_state=random_state)\n",
    "    \n",
    "    # Latih model pada data training dengan parameter terbaik\n",
    "    randomized_search.fit(x_train, y_train)\n",
    "    \n",
    "    # Menampilkan hyperparameter terbaik dan akurasi pada data training\n",
    "    print(f'{model} - Best Params from RandomizedSearchCV:', randomized_search.best_params_)\n",
    "    print(f'{model} - Best Accuracy on Training Data     :', randomized_search.best_score_)\n",
    "    \n",
    "    # Melakukan prediksi pada data test menggunakan model dengan parameter terbaik\n",
    "    best_model = randomized_search.best_estimator_\n",
    "    y_pred_test = best_model.predict(x_test)\n",
    "    \n",
    "    # Menampilkan akurasi dan classification report pada data test\n",
    "    print(f'\\n{model} - Akurasi pada data test             :', accuracy_score(y_test, y_pred_test))\n",
    "    print('Classification report:\\n', classification_report(y_test, y_pred_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lakukan evaluasi pada setiap model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogisticRegression(random_state=123) - Akurasi pada data training    : 0.6446280991735537\n",
      "LogisticRegression(random_state=123) - Akurasi pada data test        : 0.5901639344262295\n",
      "LogisticRegression(random_state=123) - Best param for GridSearchCV   : {'C': 0.1, 'max_iter': 100, 'penalty': 'l2', 'solver': 'lbfgs'}\n",
      "LogisticRegression(random_state=123) - Best accuracy on Training data: 0.5867346938775511\n",
      "\n",
      "LogisticRegression(random_state=123) - Akurasi pada data test        : 0.5737704918032787\n",
      "Classification report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.74      0.88      0.81        33\n",
      "           1       0.30      0.21      0.25        14\n",
      "           2       0.20      0.25      0.22         8\n",
      "           3       0.50      0.17      0.25         6\n",
      "\n",
      "    accuracy                           0.57        61\n",
      "   macro avg       0.44      0.38      0.38        61\n",
      "weighted avg       0.55      0.57      0.55        61\n",
      "\n",
      "LogisticRegression(random_state=123) - Best Params from RandomizedSearchCV: {'solver': 'lbfgs', 'penalty': 'l2', 'max_iter': 200, 'C': 0.1}\n",
      "LogisticRegression(random_state=123) - Best Accuracy on Training Data     : 0.5867346938775511\n",
      "\n",
      "LogisticRegression(random_state=123) - Akurasi pada data test             : 0.5737704918032787\n",
      "Classification report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.74      0.88      0.81        33\n",
      "           1       0.30      0.21      0.25        14\n",
      "           2       0.20      0.25      0.22         8\n",
      "           3       0.50      0.17      0.25         6\n",
      "\n",
      "    accuracy                           0.57        61\n",
      "   macro avg       0.44      0.38      0.38        61\n",
      "weighted avg       0.55      0.57      0.55        61\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Inisialisasi model LogisticRegression\n",
    "logreg = LogisticRegression(random_state=123)\n",
    "evaluate_model_on_train(logreg, x_train=x_train_scaled, y_train=y_train)\n",
    "\n",
    "logreg.fit(x_train_scaled, y_train)\n",
    "evaluate_model_on_test(logreg, x_test=x_test_scaled, y_test=y_test)\n",
    "\n",
    "logreg_params = {\n",
    "    'C': [0.01, 0.1, 1, 10],         # Parameter regulasi\n",
    "    'penalty': ['l2'],               # Jenis regulasi yang dipakai\n",
    "    'solver': ['lbfgs', 'liblinear'], # Algoritma optimasi\n",
    "    'max_iter': [100, 200, 300]       # Jumlah iterasi maksimal\n",
    "}\n",
    "\n",
    "# Panggil fungsi hyperparameter tuning dengan Logistic Regression dan evalusi pada data test\n",
    "evaluate_grid_tuning_on_test(logreg, param_grid=logreg_params, x_train=x_train_scaled, \n",
    "                                       y_train=y_train, x_test=x_test_scaled, y_test=y_test)\n",
    "evaluate_randomized_tuning_on_test(logreg, param_distributions=logreg_params, x_train=x_train_scaled, y_train=y_train, \n",
    "                                   x_test=x_test_scaled, y_test=y_test, cv=5, scoring='accuracy', n_iter=10, random_state=123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNeighborsClassifier() - Akurasi pada data training    : 0.6983471074380165\n",
      "KNeighborsClassifier() - Akurasi pada data test        : 0.4918032786885246\n",
      "KNeighborsClassifier() - Best param for GridSearchCV   : {'metric': 'euclidean', 'n_neighbors': 5, 'weights': 'distance'}\n",
      "KNeighborsClassifier() - Best accuracy on Training data: 0.5996598639455784\n",
      "\n",
      "KNeighborsClassifier() - Akurasi pada data test        : 0.4918032786885246\n",
      "Classification report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.69      0.76      0.72        33\n",
      "           1       0.29      0.14      0.19        14\n",
      "           2       0.22      0.25      0.24         8\n",
      "           3       0.12      0.17      0.14         6\n",
      "           4       0.00      0.00      0.00         0\n",
      "\n",
      "    accuracy                           0.49        61\n",
      "   macro avg       0.27      0.26      0.26        61\n",
      "weighted avg       0.48      0.49      0.48        61\n",
      "\n",
      "KNeighborsClassifier() - Best Params from RandomizedSearchCV: {'weights': 'distance', 'n_neighbors': 5, 'metric': 'euclidean'}\n",
      "KNeighborsClassifier() - Best Accuracy on Training Data     : 0.5996598639455784\n",
      "\n",
      "KNeighborsClassifier() - Akurasi pada data test             : 0.4918032786885246\n",
      "Classification report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.69      0.76      0.72        33\n",
      "           1       0.29      0.14      0.19        14\n",
      "           2       0.22      0.25      0.24         8\n",
      "           3       0.12      0.17      0.14         6\n",
      "           4       0.00      0.00      0.00         0\n",
      "\n",
      "    accuracy                           0.49        61\n",
      "   macro avg       0.27      0.26      0.26        61\n",
      "weighted avg       0.48      0.49      0.48        61\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Inisialisasi model KNeighborsClassifier\n",
    "knn = KNeighborsClassifier()\n",
    "evaluate_model_on_train(knn, x_train=x_train_scaled, y_train=y_train)\n",
    "\n",
    "knn.fit(x_train_scaled, y_train)\n",
    "evaluate_model_on_test(knn, x_test=x_test_scaled, y_test=y_test)\n",
    "\n",
    "knn_params = {\n",
    "    'n_neighbors': [3, 5, 7, 9], # Jumlah tetangga yang dipertimbangkan\n",
    "    'weights': ['uniform', 'distance'], # Bobot untuk tetangga\n",
    "    'metric': ['euclidean', 'manhattan', 'minkowski'] # Jenis jarak\n",
    "}\n",
    "\n",
    "# Jalankan fungsi dengan model K-Nearest Neighbors\n",
    "evaluate_grid_tuning_on_test(knn, param_grid=knn_params, x_train=x_train_scaled, \n",
    "                                       y_train=y_train, x_test=x_test_scaled, y_test=y_test)\n",
    "evaluate_randomized_tuning_on_test(knn, param_distributions=knn_params, x_train=x_train_scaled, y_train=y_train, \n",
    "                                   x_test=x_test_scaled, y_test=y_test, cv=5, scoring='accuracy', n_iter=10, random_state=123)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RandomForestClassifier(random_state=123) - Akurasi pada data training    : 1.0\n",
      "RandomForestClassifier(random_state=123) - Akurasi pada data test        : 0.5573770491803278\n",
      "RandomForestClassifier(random_state=123) - Best param for GridSearchCV   : {'max_depth': None, 'min_samples_leaf': 4, 'min_samples_split': 2, 'n_estimators': 100}\n",
      "RandomForestClassifier(random_state=123) - Best accuracy on Training data: 0.5991496598639455\n",
      "\n",
      "RandomForestClassifier(random_state=123) - Akurasi pada data test        : 0.5737704918032787\n",
      "Classification report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.69      0.94      0.79        33\n",
      "           1       0.00      0.00      0.00        14\n",
      "           2       0.33      0.12      0.18         8\n",
      "           3       0.43      0.50      0.46         6\n",
      "           4       0.00      0.00      0.00         0\n",
      "\n",
      "    accuracy                           0.57        61\n",
      "   macro avg       0.29      0.31      0.29        61\n",
      "weighted avg       0.46      0.57      0.50        61\n",
      "\n",
      "RandomForestClassifier(random_state=123) - Best Params from RandomizedSearchCV: {'n_estimators': 200, 'min_samples_split': 2, 'min_samples_leaf': 4, 'max_depth': 30}\n",
      "RandomForestClassifier(random_state=123) - Best Accuracy on Training Data     : 0.5949829931972789\n",
      "\n",
      "RandomForestClassifier(random_state=123) - Akurasi pada data test             : 0.5737704918032787\n",
      "Classification report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.70      0.91      0.79        33\n",
      "           1       0.20      0.07      0.11        14\n",
      "           2       0.29      0.25      0.27         8\n",
      "           3       0.40      0.33      0.36         6\n",
      "           4       0.00      0.00      0.00         0\n",
      "\n",
      "    accuracy                           0.57        61\n",
      "   macro avg       0.32      0.31      0.31        61\n",
      "weighted avg       0.50      0.57      0.52        61\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Inisialisasi model RandomForestClassifier\n",
    "random_forest = RandomForestClassifier(random_state=123)\n",
    "evaluate_model_on_train(random_forest, x_train=x_train_scaled, y_train=y_train)\n",
    "\n",
    "random_forest.fit(x_train_scaled, y_train)\n",
    "evaluate_model_on_test(random_forest, x_test=x_test_scaled, y_test=y_test)\n",
    "\n",
    "rf_params = {\n",
    "    'n_estimators': [100, 200, 300], # Jumlah trees\n",
    "    'max_depth': [None, 10, 20, 30], # Kedalaman tree\n",
    "    'min_samples_split': [2, 5, 10], # Minimum sampel untuk split\n",
    "    'min_samples_leaf': [1, 2, 4] # Minimum sampel di leaf node\n",
    "}\n",
    "# Panggil fungsi hyperparameter tuning dengan random forest dan evalusi pada data test\n",
    "evaluate_grid_tuning_on_test(random_forest, param_grid=rf_params, x_train=x_train_scaled, \n",
    "                                       y_train=y_train, x_test=x_test_scaled, y_test=y_test)\n",
    "evaluate_randomized_tuning_on_test(random_forest, param_distributions=rf_params, x_train=x_train_scaled, y_train=y_train, \n",
    "                                   x_test=x_test_scaled, y_test=y_test, cv=5, scoring='accuracy', n_iter=10, random_state=123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AdaBoostClassifier(random_state=123) - Akurasi pada data training    : 0.6446280991735537\n",
      "AdaBoostClassifier(random_state=123) - Akurasi pada data test        : 0.5081967213114754\n",
      "AdaBoostClassifier(random_state=123) - Best param for GridSearchCV   : {'learning_rate': 0.01, 'n_estimators': 100}\n",
      "AdaBoostClassifier(random_state=123) - Best accuracy on Training data: 0.5663265306122449\n",
      "\n",
      "AdaBoostClassifier(random_state=123) - Akurasi pada data test        : 0.5409836065573771\n",
      "Classification report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.68      0.91      0.78        33\n",
      "           1       0.25      0.07      0.11        14\n",
      "           2       0.18      0.25      0.21         8\n",
      "           3       0.00      0.00      0.00         6\n",
      "\n",
      "    accuracy                           0.54        61\n",
      "   macro avg       0.28      0.31      0.28        61\n",
      "weighted avg       0.45      0.54      0.47        61\n",
      "\n",
      "AdaBoostClassifier(random_state=123) - Best Params from RandomizedSearchCV: {'n_estimators': 100, 'learning_rate': 0.01}\n",
      "AdaBoostClassifier(random_state=123) - Best Accuracy on Training Data     : 0.5663265306122449\n",
      "\n",
      "AdaBoostClassifier(random_state=123) - Akurasi pada data test             : 0.5409836065573771\n",
      "Classification report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.68      0.91      0.78        33\n",
      "           1       0.25      0.07      0.11        14\n",
      "           2       0.18      0.25      0.21         8\n",
      "           3       0.00      0.00      0.00         6\n",
      "\n",
      "    accuracy                           0.54        61\n",
      "   macro avg       0.28      0.31      0.28        61\n",
      "weighted avg       0.45      0.54      0.47        61\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Inisialisasi model AdaBoostClassifier\n",
    "adaboost = AdaBoostClassifier(random_state=123)\n",
    "evaluate_model_on_train(adaboost, x_train=x_train_scaled, y_train=y_train)\n",
    "\n",
    "adaboost.fit(x_train_scaled, y_train)\n",
    "evaluate_model_on_test(adaboost, x_test=x_test_scaled, y_test=y_test)\n",
    "\n",
    "adaboost_params = {\n",
    "    'n_estimators': [50, 100, 200], # Jumlah estimator\n",
    "    'learning_rate': [0.01, 0.1, 1, 10] # Kecepatan belajar\n",
    "}\n",
    "# Panggil fungsi hyperparameter tuning dengan adaboost dan evalusi pada data test\n",
    "evaluate_grid_tuning_on_test(adaboost, param_grid=adaboost_params, x_train=x_train_scaled, \n",
    "                                       y_train=y_train, x_test=x_test_scaled, y_test=y_test)\n",
    "evaluate_randomized_tuning_on_test(adaboost, param_distributions=adaboost_params, x_train=x_train_scaled, y_train=y_train, \n",
    "                                   x_test=x_test_scaled, y_test=y_test, cv=5, scoring='accuracy', n_iter=10, random_state=123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVC() - Akurasi pada data training    : 0.7603305785123967\n",
      "SVC() - Akurasi pada data test        : 0.5573770491803278\n",
      "SVC() - Best param for GridSearchCV   : {'C': 1, 'gamma': 'auto', 'kernel': 'rbf'}\n",
      "SVC() - Best accuracy on Training data: 0.6113945578231292\n",
      "\n",
      "SVC() - Akurasi pada data test        : 0.5573770491803278\n",
      "Classification report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.67      0.91      0.77        33\n",
      "           1       0.33      0.21      0.26        14\n",
      "           2       0.14      0.12      0.13         8\n",
      "           3       0.00      0.00      0.00         6\n",
      "\n",
      "    accuracy                           0.56        61\n",
      "   macro avg       0.29      0.31      0.29        61\n",
      "weighted avg       0.46      0.56      0.49        61\n",
      "\n",
      "SVC() - Best Params from RandomizedSearchCV: {'kernel': 'poly', 'gamma': 'auto', 'C': 10}\n",
      "SVC() - Best Accuracy on Training Data     : 0.6031462585034014\n",
      "\n",
      "SVC() - Akurasi pada data test             : 0.5245901639344263\n",
      "Classification report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.62      0.91      0.74        33\n",
      "           1       0.12      0.07      0.09        14\n",
      "           2       0.25      0.12      0.17         8\n",
      "           3       0.00      0.00      0.00         6\n",
      "\n",
      "    accuracy                           0.52        61\n",
      "   macro avg       0.25      0.28      0.25        61\n",
      "weighted avg       0.40      0.52      0.44        61\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Inisialisasi model SVC\n",
    "svc = SVC(kernel='rbf')\n",
    "evaluate_model_on_train(svc, x_train=x_train_scaled, y_train=y_train)\n",
    "\n",
    "svc.fit(x_train_scaled, y_train)\n",
    "evaluate_model_on_test(svc, x_test=x_test_scaled, y_test=y_test)\n",
    "\n",
    "svc_params = {\n",
    "    'C': [0.1, 1, 10, 100], # Regularisasi\n",
    "    'kernel': ['linear', 'poly', 'rbf', 'sigmoid'], # Kernel function\n",
    "    'gamma': ['scale', 'auto'] # Kernel coefficient\n",
    "}\n",
    "evaluate_grid_tuning_on_test(svc, param_grid=svc_params, x_train=x_train_scaled, \n",
    "                                       y_train=y_train, x_test=x_test_scaled, y_test=y_test)\n",
    "evaluate_randomized_tuning_on_test(svc, param_distributions=svc_params, x_train=x_train_scaled, y_train=y_train, \n",
    "                                   x_test=x_test_scaled, y_test=y_test, cv=5, scoring='accuracy', n_iter=10, random_state=123)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Simpan model ke file pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['svc.pkl']"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import joblib\n",
    "\n",
    "# Simpan model logreg ke dalam folder yang sama dengan notebook\n",
    "# dengan nama logreg.pkl\n",
    "joblib.dump(knn, 'knn.pkl')\n",
    "joblib.dump(logreg, 'logreg.pkl')\n",
    "joblib.dump(random_forest, 'rf.pkl')\n",
    "joblib.dump(adaboost, 'ada.pkl')\n",
    "joblib.dump(svc, 'svc.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Insight dari Tiap-tiap Model**\n",
    "- Logistic Regression:\n",
    "    - Data Train:\n",
    "    Akurasi yang baik pada data train, menunjukkan bahwa model dapat menangani linearitas data dengan baik.\n",
    "    - Data Test:\n",
    "    Akurasi pada data test 0.5737, yang menunjukkan model ini memiliki kemampuan generalisasi yang cukup baik namun masih bisa ditingkatkan.\n",
    "    - Tuning:\n",
    "    RandomizedSearchCV memberikan peningkatan performa setelah melakukan tuning, tetapi model masih berjuang untuk menangani kelas yang lebih sulit.\n",
    "    - Insight: Logistic Regression memiliki stabilitas yang baik tetapi agak terbatas untuk data non-linear. Performa meningkat setelah tuning, tetapi model ini mungkin tidak cukup untuk memprediksi kelas minoritas dengan baik.\n",
    "\n",
    "- K-Nearest Neighbors (KNN):\n",
    "    - Data Train:\n",
    "    Akurasi training cukup tinggi, tetapi cenderung lebih rendah dibanding Random Forest atau AdaBoost.\n",
    "    - Data Test:\n",
    "    Setelah tuning, KNN memberikan akurasi yang tidak terlalu tinggi pada data test, menunjukkan model ini sensitif terhadap noise dan jarak dalam data.\n",
    "    - Tuning:\n",
    "    GridSearchCV memberikan sedikit peningkatan, namun KNN tampaknya tidak berhasil memprediksi dengan baik pada data uji karena sensitivitas terhadap data yang tidak terstandarisasi.\n",
    "    - Insight: KNN rentan terhadap outlier dan performanya menurun pada data uji. Walaupun telah dilakukan tuning, model ini masih tertinggal dibanding model lain.\n",
    "\n",
    "- Random Forest:\n",
    "    - Data Train:\n",
    "    Memiliki akurasi 100% pada data training, yang menandakan overfitting.\n",
    "    - Data Test:\n",
    "    Akurasi pada data test turun signifikan setelah dilakukan evaluasi, menunjukkan bahwa model overfit dan tidak generalisasi dengan baik.\n",
    "    - Tuning:\n",
    "    Hyperparameter tuning (baik RandomizedSearchCV maupun GridSearchCV) dapat sedikit membantu menurunkan overfitting, tetapi perbedaannya tidak terlalu signifikan pada data test.\n",
    "    - Insight: Random Forest cenderung overfitting pada data training, dan tidak memberikan generalisasi yang baik pada data test. Ini menunjukkan bahwa model ini kurang efektif untuk dataset ini.\n",
    "\n",
    "- AdaBoost:\n",
    "    - Data Train:\n",
    "    Akurasi pada data training cukup baik namun tidak mencapai 100%, yang berarti model lebih stabil dibanding Random Forest.\n",
    "    - Data Test:\n",
    "    Akurasi pada data test 0.508 menunjukkan bahwa model dapat generalisasi dengan cukup baik, meskipun ada ruang untuk perbaikan.\n",
    "    - Tuning:\n",
    "    Ada sedikit peningkatan performa setelah hyperparameter tuning, tetapi model tetap berjuang dengan kompleksitas data.\n",
    "    - Insight: AdaBoost cukup baik dalam mencegah overfitting, namun belum bisa menghasilkan hasil yang memuaskan pada data test. Model ini bekerja baik jika fitur yang dipilih lebih relevan.\n",
    "\n",
    "- Support Vector Classifier (SVC):\n",
    "    - Data Train:\n",
    "    Setelah tuning, SVC menunjukkan hasil yang baik pada data training, namun akurasi test cukup rendah.\n",
    "    - Data Test:\n",
    "    Hasil evaluasi dengan akurasi 0.4918 menunjukkan bahwa model kesulitan untuk menangani data yang tidak linear, meskipun hyperparameter tuning sudah dilakukan.\n",
    "    - Tuning:\n",
    "    GridSearchCV dengan berbagai kernel (linear, sigmoid, RBF) memperlihatkan bahwa kernel sigmoid memberikan performa terbaik, tetapi model ini masih underfitting pada data test.\n",
    "    - Insight: SVC kurang cocok untuk dataset ini, meskipun tuning sudah dilakukan. Performa model masih di bawah ekspektasi, terutama untuk prediksi pada kelas yang lebih kompleks.\n",
    "\n",
    "### Kesimpulan\n",
    "Overfitting adalah masalah utama dalam proyek ini, terutama untuk model seperti Random Forest dan XGBoost yang cenderung belajar terlalu banyak dari data training dan tidak generalisasi dengan baik pada data test.\n",
    "Class Imbalance memainkan peran besar dalam rendahnya performa recall dan f1-score pada beberapa kelas target. Model seperti Logistic Regression dan SVC berjuang dalam menangani kelas minoritas.\n",
    "Model seperti AdaBoost dan Balanced Random Forest menunjukkan potensi dalam menangani ketidakseimbangan kelas dengan lebih baik, namun tetap memerlukan tuning lebih lanjut untuk hasil yang lebih baik.\n",
    "Secara umum, Logistic Regression dan AdaBoost cenderung lebih stabil dan generalisasi lebih baik daripada model yang lebih kompleks seperti Random Forest pada dataset ini.\n",
    "\n",
    "### Model Terbaik untuk Proyek Machine Learning Heart Disease\n",
    "Berdasarkan evaluasi dari hasil hyperparameter tuning, Logistic Regression tampaknya menjadi model terbaik untuk saat ini, terutama karena stabilitasnya dan kemampuannya untuk generalisasi lebih baik dibanding model lain pada data test. Ini ditunjukkan dengan akurasi 0.5737 dan lebih sedikit kecenderungan untuk overfitting dibanding Random Forest dan KNN."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
